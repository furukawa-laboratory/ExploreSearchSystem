,Unnamed: 0,keyword,site_name,URL,snippet,ranking,target
0,0,Meta Learning,A Comprehensive Overview and Survey of Recent Advances in Meta-Learning,http://arxiv.org/abs/2004.11149v7,"This article reviews meta-learning also known as learning-to-learn which seeks rapid and accurate model adaptation to unseen tasks with applications in highly automated AI, few-shot learning, natural language processing and robotics. Unlike deep learning, meta-learning can be applied to few-shot high-dimensional datasets and considers further improving model generalization to unseen tasks. Deep learning is focused upon in-sample prediction and meta-learning concerns model adaptation for out-of-sample prediction. Meta-learning can continually perform self-improvement to achieve highly autonomous AI. Meta-learning may serve as an additional generalization block complementary for original deep learning model. Meta-learning seeks adaptation of machine learning models to unseen tasks which are vastly different from trained tasks. Meta-learning with coevolution between agent and environment provides solutions for complex tasks unsolvable by training from scratch. Meta-learning methodology covers a wide range of great minds and thoughts. We briefly introduce meta-learning methodologies in the following categories: black-box meta-learning, metric-based meta-learning, layered meta-learning and Bayesian meta-learning framework. Recent applications concentrate upon the integration of meta-learning with other machine learning framework to provide feasible integrated problem solutions. We briefly present recent meta-learning advances and discuss potential future research directions.",1,This article reviews meta learning also known as learning to learn which seeks rapid and accurate model adaptation to unseen tasks with applications in highly automated AI few shot learning natural language processing and robotics Unlike deep learning meta learning can be applied to few shot high dimensional datasets and considers further improving model generalization to unseen tasks Deep learning is focused upon in sample prediction and meta learning concerns model adaptation for out of sample prediction Meta learning can continually perform self improvement to achieve highly autonomous AI Meta learning may serve as an additional generalization block complementary for original deep learning model Meta learning seeks adaptation of machine learning models to unseen tasks which are vastly different from trained tasks Meta learning with coevolution between agent and environment provides solutions for complex tasks unsolvable by training from scratch Meta learning methodology covers a wide range of great minds and thoughts We briefly introduce meta learning methodologies in the following categories black box meta learning metric based meta learning layered meta learning and Bayesian meta learning framework Recent applications concentrate upon the integration of meta learning with other machine learning framework to provide feasible integrated problem solutions We briefly present recent meta learning advances and discuss potential future research directions
1,1,Meta Learning,"Yet Meta Learning Can Adapt Fast, It Can Also Break Easily",http://arxiv.org/abs/2009.01672v1,"Meta learning algorithms have been widely applied in many tasks for efficient learning, such as few-shot image classification and fast reinforcement learning. During meta training, the meta learner develops a common learning strategy, or experience, from a variety of learning tasks. Therefore, during meta test, the meta learner can use the learned strategy to quickly adapt to new tasks even with a few training samples. However, there is still a dark side about meta learning in terms of reliability and robustness. In particular, is meta learning vulnerable to adversarial attacks? In other words, would a well-trained meta learner utilize its learned experience to build wrong or likely useless knowledge, if an adversary unnoticeably manipulates the given training set? Without the understanding of this problem, it is extremely risky to apply meta learning in safety-critical applications. Thus, in this paper, we perform the initial study about adversarial attacks on meta learning under the few-shot classification problem. In particular, we formally define key elements of adversarial attacks unique to meta learning and propose the first attacking algorithm against meta learning under various settings. We evaluate the effectiveness of the proposed attacking strategy as well as the robustness of several representative meta learning algorithms. Experimental results demonstrate that the proposed attacking strategy can easily break the meta learner and meta learning is vulnerable to adversarial attacks. The implementation of the proposed framework will be released upon the acceptance of this paper.",2,Meta learning algorithms have been widely applied in many tasks for efficient learning such as few shot image classification and fast reinforcement learning During meta training the meta learner develops a common learning strategy or experience from a variety of learning tasks Therefore during meta test the meta learner can use the learned strategy to quickly adapt to new tasks even with a few training samples However there is still a dark side about meta learning in terms of reliability and robustness In particular is meta learning vulnerable to adversarial attacks In other words would a well trained meta learner utilize its learned experience to build wrong or likely useless knowledge if an adversary unnoticeably manipulates the given training set Without the understanding of this problem it is extremely risky to apply meta learning in safety critical applications Thus in this paper we perform the initial study about adversarial attacks on meta learning under the few shot classification problem In particular we formally define key elements of adversarial attacks unique to meta learning and propose the first attacking algorithm against meta learning under various settings We evaluate the effectiveness of the proposed attacking strategy as well as the robustness of several representative meta learning algorithms Experimental results demonstrate that the proposed attacking strategy can easily break the meta learner and meta learning is vulnerable to adversarial attacks The implementation of the proposed framework will be released upon the acceptance of this paper
2,2,Meta Learning,Meta-SGD: Learning to Learn Quickly for Few-Shot Learning,http://arxiv.org/abs/1707.09835v2,"Few-shot learning is challenging for learning algorithms that learn each task in isolation and from scratch. In contrast, meta-learning learns from many related tasks a meta-learner that can learn a new task more accurately and faster with fewer examples, where the choice of meta-learners is crucial. In this paper, we develop Meta-SGD, an SGD-like, easily trainable meta-learner that can initialize and adapt any differentiable learner in just one step, on both supervised learning and reinforcement learning. Compared to the popular meta-learner LSTM, Meta-SGD is conceptually simpler, easier to implement, and can be learned more efficiently. Compared to the latest meta-learner MAML, Meta-SGD has a much higher capacity by learning to learn not just the learner initialization, but also the learner update direction and learning rate, all in a single meta-learning process. Meta-SGD shows highly competitive performance for few-shot learning on regression, classification, and reinforcement learning.",3,Few shot learning is challenging for learning algorithms that learn each task in isolation and from scratch In contrast meta learning learns from many related tasks a meta learner that can learn a new task more accurately and faster with fewer examples where the choice of meta learners is crucial In this paper we develop Meta SGD an SGD like easily trainable meta learner that can initialize and adapt any differentiable learner in just one step on both supervised learning and reinforcement learning Compared to the popular meta learner LSTM Meta SGD is conceptually simpler easier to implement and can be learned more efficiently Compared to the latest meta learner MAML Meta SGD has a much higher capacity by learning to learn not just the learner initialization but also the learner update direction and learning rate all in a single meta learning process Meta SGD shows highly competitive performance for few shot learning on regression classification and reinforcement learning
3,3,Meta Learning,Double Meta-Learning for Data Efficient Policy Optimization in Non-Stationary Environments,http://arxiv.org/abs/2011.10714v1,"We are interested in learning models of non-stationary environments, which can be framed as a multi-task learning problem. Model-free reinforcement learning algorithms can achieve good asymptotic performance in multi-task learning at a cost of extensive sampling, due to their approach, which requires learning from scratch. While model-based approaches are among the most data efficient learning algorithms, they still struggle with complex tasks and model uncertainties. Meta-reinforcement learning addresses the efficiency and generalization challenges on multi task learning by quickly leveraging the meta-prior policy for a new task. In this paper, we propose a meta-reinforcement learning approach to learn the dynamic model of a non-stationary environment to be used for meta-policy optimization later. Due to the sample efficiency of model-based learning methods, we are able to simultaneously train both the meta-model of the non-stationary environment and the meta-policy until dynamic model convergence. Then, the meta-learned dynamic model of the environment will generate simulated data for meta-policy optimization. Our experiment demonstrates that our proposed method can meta-learn the policy in a non-stationary environment with the data efficiency of model-based learning approaches while achieving the high asymptotic performance of model-free meta-reinforcement learning.",4,We are interested in learning models of non stationary environments which can be framed as a multi task learning problem Model free reinforcement learning algorithms can achieve good asymptotic performance in multi task learning at a cost of extensive sampling due to their approach which requires learning from scratch While model based approaches are among the most data efficient learning algorithms they still struggle with complex tasks and model uncertainties Meta reinforcement learning addresses the efficiency and generalization challenges on multi task learning by quickly leveraging the meta prior policy for a new task In this paper we propose a meta reinforcement learning approach to learn the dynamic model of a non stationary environment to be used for meta policy optimization later Due to the sample efficiency of model based learning methods we are able to simultaneously train both the meta model of the non stationary environment and the meta policy until dynamic model convergence Then the meta learned dynamic model of the environment will generate simulated data for meta policy optimization Our experiment demonstrates that our proposed method can meta learn the policy in a non stationary environment with the data efficiency of model based learning approaches while achieving the high asymptotic performance of model free meta reinforcement learning
4,4,Meta Learning,Deep Meta-Learning: Learning to Learn in the Concept Space,http://arxiv.org/abs/1802.03596v1,"Few-shot learning remains challenging for meta-learning that learns a learning algorithm (meta-learner) from many related tasks. In this work, we argue that this is due to the lack of a good representation for meta-learning, and propose deep meta-learning to integrate the representation power of deep learning into meta-learning. The framework is composed of three modules, a concept generator, a meta-learner, and a concept discriminator, which are learned jointly. The concept generator, e.g. a deep residual net, extracts a representation for each instance that captures its high-level concept, on which the meta-learner performs few-shot learning, and the concept discriminator recognizes the concepts. By learning to learn in the concept space rather than in the complicated instance space, deep meta-learning can substantially improve vanilla meta-learning, which is demonstrated on various few-shot image recognition problems. For example, on 5-way-1-shot image recognition on CIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to 58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%, and improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%, respectively.",5,Few shot learning remains challenging for meta learning that learns a learning algorithm meta learner from many related tasks In this work we argue that this is due to the lack of a good representation for meta learning and propose deep meta learning to integrate the representation power of deep learning into meta learning The framework is composed of three modules a concept generator a meta learner and a concept discriminator which are learned jointly The concept generator e g a deep residual net extracts a representation for each instance that captures its high level concept on which the meta learner performs few shot learning and the concept discriminator recognizes the concepts By learning to learn in the concept space rather than in the complicated instance space deep meta learning can substantially improve vanilla meta learning which is demonstrated on various few shot image recognition problems For example on 0 way 0 shot image recognition on CIFAR 0 and CUB 0 it improves Matching Nets from 0 0 and 0 0 to 0 0 and 0 0 improves MAML from 0 0 and 0 0 to 0 0 and 0 0 and improves Meta SGD from 0 0 and 0 0 to 0 0 and 0 0 respectively
5,5,Meta Learning,Dataset2Vec: Learning Dataset Meta-Features,http://arxiv.org/abs/1905.11063v4,"Meta-learning, or learning to learn, is a machine learning approach that utilizes prior learning experiences to expedite the learning process on unseen tasks. As a data-driven approach, meta-learning requires meta-features that represent the primary learning tasks or datasets, and are estimated traditonally as engineered dataset statistics that require expert domain knowledge tailored for every meta-task. In this paper, first, we propose a meta-feature extractor called Dataset2Vec that combines the versatility of engineered dataset meta-features with the expressivity of meta-features learned by deep neural networks. Primary learning tasks or datasets are represented as hierarchical sets, i.e., as a set of sets, esp. as a set of predictor/target pairs, and then a DeepSet architecture is employed to regress meta-features on them. Second, we propose a novel auxiliary meta-learning task with abundant data called dataset similarity learning that aims to predict if two batches stem from the same dataset or different ones. In an experiment on a large-scale hyperparameter optimization task for 120 UCI datasets with varying schemas as a meta-learning task, we show that the meta-features of Dataset2Vec outperform the expert engineered meta-features and thus demonstrate the usefulness of learned meta-features for datasets with varying schemas for the first time.",6,Meta learning or learning to learn is a machine learning approach that utilizes prior learning experiences to expedite the learning process on unseen tasks As a data driven approach meta learning requires meta features that represent the primary learning tasks or datasets and are estimated traditonally as engineered dataset statistics that require expert domain knowledge tailored for every meta task In this paper first we propose a meta feature extractor called Dataset 0 Vec that combines the versatility of engineered dataset meta features with the expressivity of meta features learned by deep neural networks Primary learning tasks or datasets are represented as hierarchical sets i e as a set of sets esp as a set of predictor target pairs and then a DeepSet architecture is employed to regress meta features on them Second we propose a novel auxiliary meta learning task with abundant data called dataset similarity learning that aims to predict if two batches stem from the same dataset or different ones In an experiment on a large scale hyperparameter optimization task for 0 UCI datasets with varying schemas as a meta learning task we show that the meta features of Dataset 0 Vec outperform the expert engineered meta features and thus demonstrate the usefulness of learned meta features for datasets with varying schemas for the first time
6,6,Meta Learning,Transfer Meta-Learning: Information-Theoretic Bounds and Information Meta-Risk Minimization,http://arxiv.org/abs/2011.02872v2,"Meta-learning automatically infers an inductive bias by observing data from a number of related tasks. The inductive bias is encoded by hyperparameters that determine aspects of the model class or training algorithm, such as initialization or learning rate. Meta-learning assumes that the learning tasks belong to a task environment, and that tasks are drawn from the same task environment both during meta-training and meta-testing. This, however, may not hold true in practice. In this paper, we introduce the problem of transfer meta-learning, in which tasks are drawn from a target task environment during meta-testing that may differ from the source task environment observed during meta-training. Novel information-theoretic upper bounds are obtained on the transfer meta-generalization gap, which measures the difference between the meta-training loss, available at the meta-learner, and the average loss on meta-test data from a new, randomly selected, task in the target task environment. The first bound, on the average transfer meta-generalization gap, captures the meta-environment shift between source and target task environments via the KL divergence between source and target data distributions. The second, PAC-Bayesian bound, and the third, single-draw bound, account for this shift via the log-likelihood ratio between source and target task distributions. Furthermore, two transfer meta-learning solutions are introduced. For the first, termed Empirical Meta-Risk Minimization (EMRM), we derive bounds on the average optimality gap. The second, referred to as Information Meta-Risk Minimization (IMRM), is obtained by minimizing the PAC-Bayesian bound. IMRM is shown via experiments to potentially outperform EMRM.",7,Meta learning automatically infers an inductive bias by observing data from a number of related tasks The inductive bias is encoded by hyperparameters that determine aspects of the model class or training algorithm such as initialization or learning rate Meta learning assumes that the learning tasks belong to a task environment and that tasks are drawn from the same task environment both during meta training and meta testing This however may not hold true in practice In this paper we introduce the problem of transfer meta learning in which tasks are drawn from a target task environment during meta testing that may differ from the source task environment observed during meta training Novel information theoretic upper bounds are obtained on the transfer meta generalization gap which measures the difference between the meta training loss available at the meta learner and the average loss on meta test data from a new randomly selected task in the target task environment The first bound on the average transfer meta generalization gap captures the meta environment shift between source and target task environments via the KL divergence between source and target data distributions The second PAC Bayesian bound and the third single draw bound account for this shift via the log likelihood ratio between source and target task distributions Furthermore two transfer meta learning solutions are introduced For the first termed Empirical Meta Risk Minimization EMRM we derive bounds on the average optimality gap The second referred to as Information Meta Risk Minimization IMRM is obtained by minimizing the PAC Bayesian bound IMRM is shown via experiments to potentially outperform EMRM
7,7,Meta Learning,Unsupervised Meta-Learning for Reinforcement Learning,http://arxiv.org/abs/1806.04640v3,"Meta-learning algorithms use past experience to learn to quickly solve new tasks. In the context of reinforcement learning, meta-learning algorithms acquire reinforcement learning procedures to solve new problems more efficiently by utilizing experience from prior tasks. The performance of meta-learning algorithms depends on the tasks available for meta-training: in the same way that supervised learning generalizes best to test points drawn from the same distribution as the training points, meta-learning methods generalize best to tasks from the same distribution as the meta-training tasks. In effect, meta-reinforcement learning offloads the design burden from algorithm design to task design. If we can automate the process of task design as well, we can devise a meta-learning algorithm that is truly automated. In this work, we take a step in this direction, proposing a family of unsupervised meta-learning algorithms for reinforcement learning. We motivate and describe a general recipe for unsupervised meta-reinforcement learning, and present an instantiation of this approach. Our conceptual and theoretical contributions consist of formulating the unsupervised meta-reinforcement learning problem and describing how task proposals based on mutual information can be used to train optimal meta-learners. Our experimental results indicate that unsupervised meta-reinforcement learning effectively acquires accelerated reinforcement learning procedures without the need for manual task design and these procedures exceed the performance of learning from scratch.",8,Meta learning algorithms use past experience to learn to quickly solve new tasks In the context of reinforcement learning meta learning algorithms acquire reinforcement learning procedures to solve new problems more efficiently by utilizing experience from prior tasks The performance of meta learning algorithms depends on the tasks available for meta training in the same way that supervised learning generalizes best to test points drawn from the same distribution as the training points meta learning methods generalize best to tasks from the same distribution as the meta training tasks In effect meta reinforcement learning offloads the design burden from algorithm design to task design If we can automate the process of task design as well we can devise a meta learning algorithm that is truly automated In this work we take a step in this direction proposing a family of unsupervised meta learning algorithms for reinforcement learning We motivate and describe a general recipe for unsupervised meta reinforcement learning and present an instantiation of this approach Our conceptual and theoretical contributions consist of formulating the unsupervised meta reinforcement learning problem and describing how task proposals based on mutual information can be used to train optimal meta learners Our experimental results indicate that unsupervised meta reinforcement learning effectively acquires accelerated reinforcement learning procedures without the need for manual task design and these procedures exceed the performance of learning from scratch
8,8,Meta Learning,Incremental Meta-Learning via Indirect Discriminant Alignment,http://arxiv.org/abs/2002.04162v2,"Majority of the modern meta-learning methods for few-shot classification tasks operate in two phases: a meta-training phase where the meta-learner learns a generic representation by solving multiple few-shot tasks sampled from a large dataset and a testing phase, where the meta-learner leverages its learnt internal representation for a specific few-shot task involving classes which were not seen during the meta-training phase. To the best of our knowledge, all such meta-learning methods use a single base dataset for meta-training to sample tasks from and do not adapt the algorithm after meta-training. This strategy may not scale to real-world use-cases where the meta-learner does not potentially have access to the full meta-training dataset from the very beginning and we need to update the meta-learner in an incremental fashion when additional training data becomes available. Through our experimental setup, we develop a notion of incremental learning during the meta-training phase of meta-learning and propose a method which can be used with multiple existing metric-based meta-learning algorithms. Experimental results on benchmark dataset show that our approach performs favorably at test time as compared to training a model with the full meta-training set and incurs negligible amount of catastrophic forgetting",9,Majority of the modern meta learning methods for few shot classification tasks operate in two phases a meta training phase where the meta learner learns a generic representation by solving multiple few shot tasks sampled from a large dataset and a testing phase where the meta learner leverages its learnt internal representation for a specific few shot task involving classes which were not seen during the meta training phase To the best of our knowledge all such meta learning methods use a single base dataset for meta training to sample tasks from and do not adapt the algorithm after meta training This strategy may not scale to real world use cases where the meta learner does not potentially have access to the full meta training dataset from the very beginning and we need to update the meta learner in an incremental fashion when additional training data becomes available Through our experimental setup we develop a notion of incremental learning during the meta training phase of meta learning and propose a method which can be used with multiple existing metric based meta learning algorithms Experimental results on benchmark dataset show that our approach performs favorably at test time as compared to training a model with the full meta training set and incurs negligible amount of catastrophic forgetting
9,9,Meta Learning,A Brief Survey of Associations Between Meta-Learning and General AI,http://arxiv.org/abs/2101.04283v1,"This paper briefly reviews the history of meta-learning and describes its contribution to general AI. Meta-learning improves model generalization capacity and devises general algorithms applicable to both in-distribution and out-of-distribution tasks potentially. General AI replaces task-specific models with general algorithmic systems introducing higher level of automation in solving diverse tasks using AI. We summarize main contributions of meta-learning to the developments in general AI, including memory module, meta-learner, coevolution, curiosity, forgetting and AI-generating algorithm. We present connections between meta-learning and general AI and discuss how meta-learning can be used to formulate general AI algorithms.",10,This paper briefly reviews the history of meta learning and describes its contribution to general AI Meta learning improves model generalization capacity and devises general algorithms applicable to both in distribution and out of distribution tasks potentially General AI replaces task specific models with general algorithmic systems introducing higher level of automation in solving diverse tasks using AI We summarize main contributions of meta learning to the developments in general AI including memory module meta learner coevolution curiosity forgetting and AI generating algorithm We present connections between meta learning and general AI and discuss how meta learning can be used to formulate general AI algorithms
10,10,Meta Learning,Bootstrapped Meta-Learning,http://arxiv.org/abs/2109.04504v1,"Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem that often exhibits ill-conditioning, and myopic meta-objectives. We propose an algorithm that tackles these issues by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that the improvement is related to the target distance. Thus, by controlling curvature, the distance measure can be used to ease meta-optimization, for instance by reducing ill-conditioning. Further, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. The algorithm is versatile and easy to implement. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark, improve upon MAML in few-shot learning, and demonstrate how our approach opens up new possibilities by meta-learning efficient exploration in a Q-learning agent.",11,Meta learning empowers artificial intelligence to increase its efficiency by learning how to learn Unlocking this potential involves overcoming a challenging meta optimisation problem that often exhibits ill conditioning and myopic meta objectives We propose an algorithm that tackles these issues by letting the meta learner teach itself The algorithm first bootstraps a target from the meta learner then optimises the meta learner by minimising the distance to that target under a chosen pseudo metric Focusing on meta learning with gradients we establish conditions that guarantee performance improvements and show that the improvement is related to the target distance Thus by controlling curvature the distance measure can be used to ease meta optimization for instance by reducing ill conditioning Further the bootstrapping mechanism can extend the effective meta learning horizon without requiring backpropagation through all updates The algorithm is versatile and easy to implement We achieve a new state of the art for model free agents on the Atari ALE benchmark improve upon MAML in few shot learning and demonstrate how our approach opens up new possibilities by meta learning efficient exploration in a Q learning agent
11,11,Meta Learning,Meta-Learning Reliable Priors in the Function Space,http://arxiv.org/abs/2106.03195v1,"Meta-Learning promises to enable more data-efficient inference by harnessing previous experience from related learning tasks. While existing meta-learning methods help us to improve the accuracy of our predictions in face of data scarcity, they fail to supply reliable uncertainty estimates, often being grossly overconfident in their predictions. Addressing these shortcomings, we introduce a novel meta-learning framework, called F-PACOH, that treats meta-learned priors as stochastic processes and performs meta-level regularization directly in the function space. This allows us to directly steer the probabilistic predictions of the meta-learner towards high epistemic uncertainty in regions of insufficient meta-training data and, thus, obtain well-calibrated uncertainty estimates. Finally, we showcase how our approach can be integrated with sequential decision making, where reliable uncertainty quantification is imperative. In our benchmark study on meta-learning for Bayesian Optimization (BO), F-PACOH significantly outperforms all other meta-learners and standard baselines. Even in a challenging lifelong BO setting, where optimization tasks arrive one at a time and the meta-learner needs to build up informative prior knowledge incrementally, our proposed method demonstrates strong positive transfer.",12,Meta Learning promises to enable more data efficient inference by harnessing previous experience from related learning tasks While existing meta learning methods help us to improve the accuracy of our predictions in face of data scarcity they fail to supply reliable uncertainty estimates often being grossly overconfident in their predictions Addressing these shortcomings we introduce a novel meta learning framework called F PACOH that treats meta learned priors as stochastic processes and performs meta level regularization directly in the function space This allows us to directly steer the probabilistic predictions of the meta learner towards high epistemic uncertainty in regions of insufficient meta training data and thus obtain well calibrated uncertainty estimates Finally we showcase how our approach can be integrated with sequential decision making where reliable uncertainty quantification is imperative In our benchmark study on meta learning for Bayesian Optimization BO F PACOH significantly outperforms all other meta learners and standard baselines Even in a challenging lifelong BO setting where optimization tasks arrive one at a time and the meta learner needs to build up informative prior knowledge incrementally our proposed method demonstrates strong positive transfer
12,12,Meta Learning,Variable-Shot Adaptation for Online Meta-Learning,http://arxiv.org/abs/2012.07769v1,"Few-shot meta-learning methods consider the problem of learning new tasks from a small, fixed number of examples, by meta-learning across static data from a set of previous tasks. However, in many real world settings, it is more natural to view the problem as one of minimizing the total amount of supervision --- both the number of examples needed to learn a new task and the amount of data needed for meta-learning. Such a formulation can be studied in a sequential learning setting, where tasks are presented in sequence. When studying meta-learning in this online setting, a critical question arises: can meta-learning improve over the sample complexity and regret of standard empirical risk minimization methods, when considering both meta-training and adaptation together? The answer is particularly non-obvious for meta-learning algorithms with complex bi-level optimizations that may demand large amounts of meta-training data. To answer this question, we extend previous meta-learning algorithms to handle the variable-shot settings that naturally arise in sequential learning: from many-shot learning at the start, to zero-shot learning towards the end. On sequential learning problems, we find that meta-learning solves the full task set with fewer overall labels and achieves greater cumulative performance, compared to standard supervised methods. These results suggest that meta-learning is an important ingredient for building learning systems that continuously learn and improve over a sequence of problems.",13,Few shot meta learning methods consider the problem of learning new tasks from a small fixed number of examples by meta learning across static data from a set of previous tasks However in many real world settings it is more natural to view the problem as one of minimizing the total amount of supervision both the number of examples needed to learn a new task and the amount of data needed for meta learning Such a formulation can be studied in a sequential learning setting where tasks are presented in sequence When studying meta learning in this online setting a critical question arises can meta learning improve over the sample complexity and regret of standard empirical risk minimization methods when considering both meta training and adaptation together The answer is particularly non obvious for meta learning algorithms with complex bi level optimizations that may demand large amounts of meta training data To answer this question we extend previous meta learning algorithms to handle the variable shot settings that naturally arise in sequential learning from many shot learning at the start to zero shot learning towards the end On sequential learning problems we find that meta learning solves the full task set with fewer overall labels and achieves greater cumulative performance compared to standard supervised methods These results suggest that meta learning is an important ingredient for building learning systems that continuously learn and improve over a sequence of problems
13,13,Meta Learning,HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning Problem,http://arxiv.org/abs/2002.04238v2,"In spite of the success of existing meta reinforcement learning methods, they still have difficulty in learning a meta policy effectively for RL problems with sparse reward. In this respect, we develop a novel meta reinforcement learning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems. It is consisted with three modules including the cross-environment meta state embedding module which constructs a common meta state space to adapt to different environments; the meta state based environment-specific meta reward shaping which effectively extends the original sparse reward trajectory by cross-environmental knowledge complementarity and as a consequence the meta policy achieves better generalization and efficiency with the shaped meta reward. Experiments with sparse-reward environments show the superiority of HMRL on both transferability and policy learning efficiency.",14,In spite of the success of existing meta reinforcement learning methods they still have difficulty in learning a meta policy effectively for RL problems with sparse reward In this respect we develop a novel meta reinforcement learning framework called Hyper Meta RL HMRL for sparse reward RL problems It is consisted with three modules including the cross environment meta state embedding module which constructs a common meta state space to adapt to different environments the meta state based environment specific meta reward shaping which effectively extends the original sparse reward trajectory by cross environmental knowledge complementarity and as a consequence the meta policy achieves better generalization and efficiency with the shaped meta reward Experiments with sparse reward environments show the superiority of HMRL on both transferability and policy learning efficiency
14,14,Meta Learning,Offline Meta-Reinforcement Learning with Advantage Weighting,http://arxiv.org/abs/2008.06043v3,"This paper introduces the offline meta-reinforcement learning (offline meta-RL) problem setting and proposes an algorithm that performs well in this setting. Offline meta-RL is analogous to the widely successful supervised learning strategy of pre-training a model on a large batch of fixed, pre-collected data (possibly from various tasks) and fine-tuning the model to a new task with relatively little data. That is, in offline meta-RL, we meta-train on fixed, pre-collected data from several tasks in order to adapt to a new task with a very small amount (less than 5 trajectories) of data from the new task. By nature of being offline, algorithms for offline meta-RL can utilize the largest possible pool of training data available and eliminate potentially unsafe or costly data collection during meta-training. This setting inherits the challenges of offline RL, but it differs significantly because offline RL does not generally consider a) transfer to new tasks or b) limited data from the test task, both of which we face in offline meta-RL. Targeting the offline meta-RL setting, we propose Meta-Actor Critic with Advantage Weighting (MACAW), an optimization-based meta-learning algorithm that uses simple, supervised regression objectives for both the inner and outer loop of meta-training. On offline variants of common meta-RL benchmarks, we empirically find that this approach enables fully offline meta-reinforcement learning and achieves notable gains over prior methods.",15,This paper introduces the offline meta reinforcement learning offline meta RL problem setting and proposes an algorithm that performs well in this setting Offline meta RL is analogous to the widely successful supervised learning strategy of pre training a model on a large batch of fixed pre collected data possibly from various tasks and fine tuning the model to a new task with relatively little data That is in offline meta RL we meta train on fixed pre collected data from several tasks in order to adapt to a new task with a very small amount less than 0 trajectories of data from the new task By nature of being offline algorithms for offline meta RL can utilize the largest possible pool of training data available and eliminate potentially unsafe or costly data collection during meta training This setting inherits the challenges of offline RL but it differs significantly because offline RL does not generally consider a transfer to new tasks or b limited data from the test task both of which we face in offline meta RL Targeting the offline meta RL setting we propose Meta Actor Critic with Advantage Weighting MACAW an optimization based meta learning algorithm that uses simple supervised regression objectives for both the inner and outer loop of meta training On offline variants of common meta RL benchmarks we empirically find that this approach enables fully offline meta reinforcement learning and achieves notable gains over prior methods
15,15,Meta Learning,Task-Agnostic Meta-Learning for Few-shot Learning,http://arxiv.org/abs/1805.07722v1,"Meta-learning approaches have been proposed to tackle the few-shot learning problem.Typically, a meta-learner is trained on a variety of tasks in the hopes of being generalizable to new tasks. However, the generalizability on new tasks of a meta-learner could be fragile when it is over-trained on existing tasks during meta-training phase. In other words, the initial model of a meta-learner could be too biased towards existing tasks to adapt to new tasks, especially when only very few examples are available to update the model. To avoid a biased meta-learner and improve its generalizability, we propose a novel paradigm of Task-Agnostic Meta-Learning (TAML) algorithms. Specifically, we present an entropy-based approach that meta-learns an unbiased initial model with the largest uncertainty over the output labels by preventing it from over-performing in classification tasks. Alternatively, a more general inequality-minimization TAML is presented for more ubiquitous scenarios by directly minimizing the inequality of initial losses beyond the classification tasks wherever a suitable loss can be defined.Experiments on benchmarked datasets demonstrate that the proposed approaches outperform compared meta-learning algorithms in both few-shot classification and reinforcement learning tasks.",16,Meta learning approaches have been proposed to tackle the few shot learning problem Typically a meta learner is trained on a variety of tasks in the hopes of being generalizable to new tasks However the generalizability on new tasks of a meta learner could be fragile when it is over trained on existing tasks during meta training phase In other words the initial model of a meta learner could be too biased towards existing tasks to adapt to new tasks especially when only very few examples are available to update the model To avoid a biased meta learner and improve its generalizability we propose a novel paradigm of Task Agnostic Meta Learning TAML algorithms Specifically we present an entropy based approach that meta learns an unbiased initial model with the largest uncertainty over the output labels by preventing it from over performing in classification tasks Alternatively a more general inequality minimization TAML is presented for more ubiquitous scenarios by directly minimizing the inequality of initial losses beyond the classification tasks wherever a suitable loss can be defined Experiments on benchmarked datasets demonstrate that the proposed approaches outperform compared meta learning algorithms in both few shot classification and reinforcement learning tasks
16,16,Meta Learning,Learning to Recommend via Meta Parameter Partition,http://arxiv.org/abs/1912.04108v1,"In this paper we propose to solve an important problem in recommendation -- user cold start, based on meta leaning method. Previous meta learning approaches finetune all parameters for each new user, which is both computing and storage expensive. In contrast, we divide model parameters into fixed and adaptive parts and develop a two-stage meta learning algorithm to learn them separately. The fixed part, capturing user invariant features, is shared by all users and is learned during offline meta learning stage. The adaptive part, capturing user specific features, is learned during online meta learning stage. By decoupling user invariant parameters from user dependent parameters, the proposed approach is more efficient and storage cheaper than previous methods. It also has potential to deal with catastrophic forgetting while continually adapting for streaming coming users.   Experiments on production data demonstrates that the proposed method converges faster and to a better performance than baseline methods. Meta-training without online meta model finetuning increases the AUC from 72.24% to 74.72% (2.48% absolute improvement). Online meta training achieves a further gain of 2.46\% absolute improvement comparing with offline meta training.",17,In this paper we propose to solve an important problem in recommendation user cold start based on meta leaning method Previous meta learning approaches finetune all parameters for each new user which is both computing and storage expensive In contrast we divide model parameters into fixed and adaptive parts and develop a two stage meta learning algorithm to learn them separately The fixed part capturing user invariant features is shared by all users and is learned during offline meta learning stage The adaptive part capturing user specific features is learned during online meta learning stage By decoupling user invariant parameters from user dependent parameters the proposed approach is more efficient and storage cheaper than previous methods It also has potential to deal with catastrophic forgetting while continually adapting for streaming coming users Experiments on production data demonstrates that the proposed method converges faster and to a better performance than baseline methods Meta training without online meta model finetuning increases the AUC from 0 0 to 0 0 0 0 absolute improvement Online meta training achieves a further gain of 0 0 absolute improvement comparing with offline meta training
17,17,Meta Learning,Meta-Meta Classification for One-Shot Learning,http://arxiv.org/abs/2004.08083v4,"We present a new approach, called meta-meta classification, to learning in small-data settings. In this approach, one uses a large set of learning problems to design an ensemble of learners, where each learner has high bias and low variance and is skilled at solving a specific type of learning problem. The meta-meta classifier learns how to examine a given learning problem and combine the various learners to solve the problem. The meta-meta learning approach is especially suited to solving few-shot learning tasks, as it is easier to learn to classify a new learning problem with little data than it is to apply a learning algorithm to a small data set. We evaluate the approach on a one-shot, one-class-versus-all classification task and show that it is able to outperform traditional meta-learning as well as ensembling approaches.",18,We present a new approach called meta meta classification to learning in small data settings In this approach one uses a large set of learning problems to design an ensemble of learners where each learner has high bias and low variance and is skilled at solving a specific type of learning problem The meta meta classifier learns how to examine a given learning problem and combine the various learners to solve the problem The meta meta learning approach is especially suited to solving few shot learning tasks as it is easier to learn to classify a new learning problem with little data than it is to apply a learning algorithm to a small data set We evaluate the approach on a one shot one class versus all classification task and show that it is able to outperform traditional meta learning as well as ensembling approaches
18,18,Meta Learning,Meta-learning PINN loss functions,http://arxiv.org/abs/2107.05544v1,"We propose a meta-learning technique for offline discovery of physics-informed neural network (PINN) loss functions. We extend earlier works on meta-learning, and develop a gradient-based meta-learning algorithm for addressing diverse task distributions based on parametrized partial differential equations (PDEs) that are solved with PINNs. Furthermore, based on new theory we identify two desirable properties of meta-learned losses in PINN problems, which we enforce by proposing a new regularization method or using a specific parametrization of the loss function. In the computational examples, the meta-learned losses are employed at test time for addressing regression and PDE task distributions. Our results indicate that significant performance improvement can be achieved by using a shared-among-tasks offline-learned loss function even for out-of-distribution meta-testing. In this case, we solve for test tasks that do not belong to the task distribution used in meta-training, and we also employ PINN architectures that are different from the PINN architecture used in meta-training. To better understand the capabilities and limitations of the proposed method, we consider various parametrizations of the loss function and describe different algorithm design options and how they may affect meta-learning performance.",19,We propose a meta learning technique for offline discovery of physics informed neural network PINN loss functions We extend earlier works on meta learning and develop a gradient based meta learning algorithm for addressing diverse task distributions based on parametrized partial differential equations PDEs that are solved with PINNs Furthermore based on new theory we identify two desirable properties of meta learned losses in PINN problems which we enforce by proposing a new regularization method or using a specific parametrization of the loss function In the computational examples the meta learned losses are employed at test time for addressing regression and PDE task distributions Our results indicate that significant performance improvement can be achieved by using a shared among tasks offline learned loss function even for out of distribution meta testing In this case we solve for test tasks that do not belong to the task distribution used in meta training and we also employ PINN architectures that are different from the PINN architecture used in meta training To better understand the capabilities and limitations of the proposed method we consider various parametrizations of the loss function and describe different algorithm design options and how they may affect meta learning performance
19,19,Meta Learning,Meta-learning Amidst Heterogeneity and Ambiguity,http://arxiv.org/abs/2107.02228v1,"Meta-learning aims to learn a model that can handle multiple tasks generated from an unknown but shared distribution. However, typical meta-learning algorithms have assumed the tasks to be similar such that a single meta-learner is sufficient to aggregate the variations in all aspects. In addition, there has been less consideration on uncertainty when limited information is given as context. In this paper, we devise a novel meta-learning framework, called Meta-learning Amidst Heterogeneity and Ambiguity (MAHA), that outperforms previous works in terms of prediction based on its ability on task identification. By extensively conducting several experiments in regression and classification, we demonstrate the validity of our model, which turns out to be robust to both task heterogeneity and ambiguity.",20,Meta learning aims to learn a model that can handle multiple tasks generated from an unknown but shared distribution However typical meta learning algorithms have assumed the tasks to be similar such that a single meta learner is sufficient to aggregate the variations in all aspects In addition there has been less consideration on uncertainty when limited information is given as context In this paper we devise a novel meta learning framework called Meta learning Amidst Heterogeneity and Ambiguity MAHA that outperforms previous works in terms of prediction based on its ability on task identification By extensively conducting several experiments in regression and classification we demonstrate the validity of our model which turns out to be robust to both task heterogeneity and ambiguity
20,20,Meta Learning,Automated Relational Meta-learning,http://arxiv.org/abs/2001.00745v1,"In order to efficiently learn with small amount of data on new tasks, meta-learning transfers knowledge learned from previous tasks to the new ones. However, a critical challenge in meta-learning is the task heterogeneity which cannot be well handled by traditional globally shared meta-learning methods. In addition, current task-specific meta-learning methods may either suffer from hand-crafted structure design or lack the capability to capture complex relations between tasks. In this paper, motivated by the way of knowledge organization in knowledge bases, we propose an automated relational meta-learning (ARML) framework that automatically extracts the cross-task relations and constructs the meta-knowledge graph. When a new task arrives, it can quickly find the most relevant structure and tailor the learned structure knowledge to the meta-learner. As a result, the proposed framework not only addresses the challenge of task heterogeneity by a learned meta-knowledge graph, but also increases the model interpretability. We conduct extensive experiments on 2D toy regression and few-shot image classification and the results demonstrate the superiority of ARML over state-of-the-art baselines.",21,In order to efficiently learn with small amount of data on new tasks meta learning transfers knowledge learned from previous tasks to the new ones However a critical challenge in meta learning is the task heterogeneity which cannot be well handled by traditional globally shared meta learning methods In addition current task specific meta learning methods may either suffer from hand crafted structure design or lack the capability to capture complex relations between tasks In this paper motivated by the way of knowledge organization in knowledge bases we propose an automated relational meta learning ARML framework that automatically extracts the cross task relations and constructs the meta knowledge graph When a new task arrives it can quickly find the most relevant structure and tailor the learned structure knowledge to the meta learner As a result the proposed framework not only addresses the challenge of task heterogeneity by a learned meta knowledge graph but also increases the model interpretability We conduct extensive experiments on 0 D toy regression and few shot image classification and the results demonstrate the superiority of ARML over state of the art baselines
21,21,Meta Learning,Local Nonparametric Meta-Learning,http://arxiv.org/abs/2002.03272v1,"A central goal of meta-learning is to find a learning rule that enables fast adaptation across a set of tasks, by learning the appropriate inductive bias for that set. Most meta-learning algorithms try to find a \textit{global} learning rule that encodes this inductive bias. However, a global learning rule represented by a fixed-size representation is prone to meta-underfitting or -overfitting since the right representational power for a task set is difficult to choose a priori. Even when chosen correctly, we show that global, fixed-size representations often fail when confronted with certain types of out-of-distribution tasks, even when the same inductive bias is appropriate. To address these problems, we propose a novel nonparametric meta-learning algorithm that utilizes a meta-trained local learning rule, building on recent ideas in attention-based and functional gradient-based meta-learning. In several meta-regression problems, we show improved meta-generalization results using our local, nonparametric approach and achieve state-of-the-art results in the robotics benchmark, Omnipush.",22,A central goal of meta learning is to find a learning rule that enables fast adaptation across a set of tasks by learning the appropriate inductive bias for that set Most meta learning algorithms try to find a textit global learning rule that encodes this inductive bias However a global learning rule represented by a fixed size representation is prone to meta underfitting or overfitting since the right representational power for a task set is difficult to choose a priori Even when chosen correctly we show that global fixed size representations often fail when confronted with certain types of out of distribution tasks even when the same inductive bias is appropriate To address these problems we propose a novel nonparametric meta learning algorithm that utilizes a meta trained local learning rule building on recent ideas in attention based and functional gradient based meta learning In several meta regression problems we show improved meta generalization results using our local nonparametric approach and achieve state of the art results in the robotics benchmark Omnipush
22,22,Meta Learning,Improving Context-Based Meta-Reinforcement Learning with Self-Supervised Trajectory Contrastive Learning,http://arxiv.org/abs/2103.06386v1,"Meta-reinforcement learning typically requires orders of magnitude more samples than single task reinforcement learning methods. This is because meta-training needs to deal with more diverse distributions and train extra components such as context encoders. To address this, we propose a novel self-supervised learning task, which we named Trajectory Contrastive Learning (TCL), to improve meta-training. TCL adopts contrastive learning and trains a context encoder to predict whether two transition windows are sampled from the same trajectory. TCL leverages the natural hierarchical structure of context-based meta-RL and makes minimal assumptions, allowing it to be generally applicable to context-based meta-RL algorithms. It accelerates the training of context encoders and improves meta-training overall. Experiments show that TCL performs better or comparably than a strong meta-RL baseline in most of the environments on both meta-RL MuJoCo (5 of 6) and Meta-World benchmarks (44 out of 50).",23,Meta reinforcement learning typically requires orders of magnitude more samples than single task reinforcement learning methods This is because meta training needs to deal with more diverse distributions and train extra components such as context encoders To address this we propose a novel self supervised learning task which we named Trajectory Contrastive Learning TCL to improve meta training TCL adopts contrastive learning and trains a context encoder to predict whether two transition windows are sampled from the same trajectory TCL leverages the natural hierarchical structure of context based meta RL and makes minimal assumptions allowing it to be generally applicable to context based meta RL algorithms It accelerates the training of context encoders and improves meta training overall Experiments show that TCL performs better or comparably than a strong meta RL baseline in most of the environments on both meta RL MuJoCo 0 of 0 and Meta World benchmarks 0 out of 0
23,23,Meta Learning,Few-shot Learning with Meta Metric Learners,http://arxiv.org/abs/1901.09890v1,"Few-shot Learning aims to learn classifiers for new classes with only a few training examples per class. Existing meta-learning or metric-learning based few-shot learning approaches are limited in handling diverse domains with various number of labels. The meta-learning approaches train a meta learner to predict weights of homogeneous-structured task-specific networks, requiring a uniform number of classes across tasks. The metric-learning approaches learn one task-invariant metric for all the tasks, and they fail if the tasks diverge. We propose to deal with these limitations with meta metric learning. Our meta metric learning approach consists of task-specific learners, that exploit metric learning to handle flexible labels, and a meta learner, that discovers good parameters and gradient decent to specify the metrics in task-specific learners. Thus the proposed model is able to handle unbalanced classes as well as to generate task-specific metrics. We test our approach in the `$k$-shot $N$-way' few-shot learning setting used in previous work and new realistic few-shot setting with diverse multi-domain tasks and flexible label numbers. Experiments show that our approach attains superior performances in both settings.",24,Few shot Learning aims to learn classifiers for new classes with only a few training examples per class Existing meta learning or metric learning based few shot learning approaches are limited in handling diverse domains with various number of labels The meta learning approaches train a meta learner to predict weights of homogeneous structured task specific networks requiring a uniform number of classes across tasks The metric learning approaches learn one task invariant metric for all the tasks and they fail if the tasks diverge We propose to deal with these limitations with meta metric learning Our meta metric learning approach consists of task specific learners that exploit metric learning to handle flexible labels and a meta learner that discovers good parameters and gradient decent to specify the metrics in task specific learners Thus the proposed model is able to handle unbalanced classes as well as to generate task specific metrics We test our approach in the k shot N way few shot learning setting used in previous work and new realistic few shot setting with diverse multi domain tasks and flexible label numbers Experiments show that our approach attains superior performances in both settings
24,24,Meta Learning,A Brief Summary of Interactions Between Meta-Learning and Self-Supervised Learning,http://arxiv.org/abs/2103.00845v1,"This paper briefly reviews the connections between meta-learning and self-supervised learning. Meta-learning can be applied to improve model generalization capability and to construct general AI algorithms. Self-supervised learning utilizes self-supervision from original data and extracts higher-level generalizable features through unsupervised pre-training or optimization of contrastive loss objectives. In self-supervised learning, data augmentation techniques are widely applied and data labels are not required since pseudo labels can be estimated from trained models on similar tasks. Meta-learning aims to adapt trained deep models to solve diverse tasks and to develop general AI algorithms. We review the associations of meta-learning with both generative and contrastive self-supervised learning models. Unlabeled data from multiple sources can be jointly considered even when data sources are vastly different. We show that an integration of meta-learning and self-supervised learning models can best contribute to the improvement of model generalization capability. Self-supervised learning guided by meta-learner and general meta-learning algorithms under self-supervision are both examples of possible combinations.",25,This paper briefly reviews the connections between meta learning and self supervised learning Meta learning can be applied to improve model generalization capability and to construct general AI algorithms Self supervised learning utilizes self supervision from original data and extracts higher level generalizable features through unsupervised pre training or optimization of contrastive loss objectives In self supervised learning data augmentation techniques are widely applied and data labels are not required since pseudo labels can be estimated from trained models on similar tasks Meta learning aims to adapt trained deep models to solve diverse tasks and to develop general AI algorithms We review the associations of meta learning with both generative and contrastive self supervised learning models Unlabeled data from multiple sources can be jointly considered even when data sources are vastly different We show that an integration of meta learning and self supervised learning models can best contribute to the improvement of model generalization capability Self supervised learning guided by meta learner and general meta learning algorithms under self supervision are both examples of possible combinations
25,25,Meta Learning,Towards Understanding Generalization in Gradient-Based Meta-Learning,http://arxiv.org/abs/1907.07287v1,"In this work we study generalization of neural networks in gradient-based meta-learning by analyzing various properties of the objective landscapes. We experimentally demonstrate that as meta-training progresses, the meta-test solutions, obtained after adapting the meta-train solution of the model, to new tasks via few steps of gradient-based fine-tuning, become flatter, lower in loss, and further away from the meta-train solution. We also show that those meta-test solutions become flatter even as generalization starts to degrade, thus providing an experimental evidence against the correlation between generalization and flat minima in the paradigm of gradient-based meta-leaning. Furthermore, we provide empirical evidence that generalization to new tasks is correlated with the coherence between their adaptation trajectories in parameter space, measured by the average cosine similarity between task-specific trajectory directions, starting from a same meta-train solution. We also show that coherence of meta-test gradients, measured by the average inner product between the task-specific gradient vectors evaluated at meta-train solution, is also correlated with generalization. Based on these observations, we propose a novel regularizer for MAML and provide experimental evidence for its effectiveness.",26,In this work we study generalization of neural networks in gradient based meta learning by analyzing various properties of the objective landscapes We experimentally demonstrate that as meta training progresses the meta test solutions obtained after adapting the meta train solution of the model to new tasks via few steps of gradient based fine tuning become flatter lower in loss and further away from the meta train solution We also show that those meta test solutions become flatter even as generalization starts to degrade thus providing an experimental evidence against the correlation between generalization and flat minima in the paradigm of gradient based meta leaning Furthermore we provide empirical evidence that generalization to new tasks is correlated with the coherence between their adaptation trajectories in parameter space measured by the average cosine similarity between task specific trajectory directions starting from a same meta train solution We also show that coherence of meta test gradients measured by the average inner product between the task specific gradient vectors evaluated at meta train solution is also correlated with generalization Based on these observations we propose a novel regularizer for MAML and provide experimental evidence for its effectiveness
26,26,Meta Learning,A Theoretical Analysis of the Number of Shots in Few-Shot Learning,http://arxiv.org/abs/1909.11722v2,"Few-shot classification is the task of predicting the category of an example from a set of few labeled examples. The number of labeled examples per category is called the number of shots (or shot number). Recent works tackle this task through meta-learning, where a meta-learner extracts information from observed tasks during meta-training to quickly adapt to new tasks during meta-testing. In this formulation, the number of shots exploited during meta-training has an impact on the recognition performance at meta-test time. Generally, the shot number used in meta-training should match the one used in meta-testing to obtain the best performance. We introduce a theoretical analysis of the impact of the shot number on Prototypical Networks, a state-of-the-art few-shot classification method. From our analysis, we propose a simple method that is robust to the choice of shot number used during meta-training, which is a crucial hyperparameter. The performance of our model trained for an arbitrary meta-training shot number shows great performance for different values of meta-testing shot numbers. We experimentally demonstrate our approach on different few-shot classification benchmarks.",27,Few shot classification is the task of predicting the category of an example from a set of few labeled examples The number of labeled examples per category is called the number of shots or shot number Recent works tackle this task through meta learning where a meta learner extracts information from observed tasks during meta training to quickly adapt to new tasks during meta testing In this formulation the number of shots exploited during meta training has an impact on the recognition performance at meta test time Generally the shot number used in meta training should match the one used in meta testing to obtain the best performance We introduce a theoretical analysis of the impact of the shot number on Prototypical Networks a state of the art few shot classification method From our analysis we propose a simple method that is robust to the choice of shot number used during meta training which is a crucial hyperparameter The performance of our model trained for an arbitrary meta training shot number shows great performance for different values of meta testing shot numbers We experimentally demonstrate our approach on different few shot classification benchmarks
27,27,Meta Learning,Learning an Explicit Hyperparameter Prediction Policy Conditioned on Tasks,http://arxiv.org/abs/2107.02378v1,"Meta learning has attracted much attention recently in machine learning community. Contrary to conventional machine learning aiming to learn inherent prediction rules to predict labels for new query data, meta learning aims to learn the learning methodology for machine learning from observed tasks, so as to generalize to new query tasks by leveraging the meta-learned learning methodology. In this study, we interpret such learning methodology as learning an explicit hyperparameter prediction policy shared by all training tasks. Specifically, this policy is represented as a parameterized function called meta-learner, mapping from a training/test task to its suitable hyperparameter setting, extracted from a pre-specified function set called meta learning machine. Such setting guarantees that the meta-learned learning methodology is able to flexibly fit diverse query tasks, instead of only obtaining fixed hyperparameters by many current meta learning methods, with less adaptability to query task's variations. Such understanding of meta learning also makes it easily succeed from traditional learning theory for analyzing its generalization bounds with general losses/tasks/models. The theory naturally leads to some feasible controlling strategies for ameliorating the quality of the extracted meta-learner, verified to be able to finely ameliorate its generalization capability in some typical meta learning applications, including few-shot regression, few-shot classification and domain generalization.",28,Meta learning has attracted much attention recently in machine learning community Contrary to conventional machine learning aiming to learn inherent prediction rules to predict labels for new query data meta learning aims to learn the learning methodology for machine learning from observed tasks so as to generalize to new query tasks by leveraging the meta learned learning methodology In this study we interpret such learning methodology as learning an explicit hyperparameter prediction policy shared by all training tasks Specifically this policy is represented as a parameterized function called meta learner mapping from a training test task to its suitable hyperparameter setting extracted from a pre specified function set called meta learning machine Such setting guarantees that the meta learned learning methodology is able to flexibly fit diverse query tasks instead of only obtaining fixed hyperparameters by many current meta learning methods with less adaptability to query task s variations Such understanding of meta learning also makes it easily succeed from traditional learning theory for analyzing its generalization bounds with general losses tasks models The theory naturally leads to some feasible controlling strategies for ameliorating the quality of the extracted meta learner verified to be able to finely ameliorate its generalization capability in some typical meta learning applications including few shot regression few shot classification and domain generalization
28,28,Meta Learning,Online Structured Meta-learning,http://arxiv.org/abs/2010.11545v1,"Learning quickly is of great importance for machine intelligence deployed in online platforms. With the capability of transferring knowledge from learned tasks, meta-learning has shown its effectiveness in online scenarios by continuously updating the model with the learned prior. However, current online meta-learning algorithms are limited to learn a globally-shared meta-learner, which may lead to sub-optimal results when the tasks contain heterogeneous information that are distinct by nature and difficult to share. We overcome this limitation by proposing an online structured meta-learning (OSML) framework. Inspired by the knowledge organization of human and hierarchical feature representation, OSML explicitly disentangles the meta-learner as a meta-hierarchical graph with different knowledge blocks. When a new task is encountered, it constructs a meta-knowledge pathway by either utilizing the most relevant knowledge blocks or exploring new blocks. Through the meta-knowledge pathway, the model is able to quickly adapt to the new task. In addition, new knowledge is further incorporated into the selected blocks. Experiments on three datasets demonstrate the effectiveness and interpretability of our proposed framework in the context of both homogeneous and heterogeneous tasks.",29,Learning quickly is of great importance for machine intelligence deployed in online platforms With the capability of transferring knowledge from learned tasks meta learning has shown its effectiveness in online scenarios by continuously updating the model with the learned prior However current online meta learning algorithms are limited to learn a globally shared meta learner which may lead to sub optimal results when the tasks contain heterogeneous information that are distinct by nature and difficult to share We overcome this limitation by proposing an online structured meta learning OSML framework Inspired by the knowledge organization of human and hierarchical feature representation OSML explicitly disentangles the meta learner as a meta hierarchical graph with different knowledge blocks When a new task is encountered it constructs a meta knowledge pathway by either utilizing the most relevant knowledge blocks or exploring new blocks Through the meta knowledge pathway the model is able to quickly adapt to the new task In addition new knowledge is further incorporated into the selected blocks Experiments on three datasets demonstrate the effectiveness and interpretability of our proposed framework in the context of both homogeneous and heterogeneous tasks
29,29,Meta Learning,Introducing Symmetries to Black Box Meta Reinforcement Learning,http://arxiv.org/abs/2109.10781v1,"Meta reinforcement learning (RL) attempts to discover new RL algorithms automatically from environment interaction. In so-called black-box approaches, the policy and the learning algorithm are jointly represented by a single neural network. These methods are very flexible, but they tend to underperform in terms of generalisation to new, unseen environments. In this paper, we explore the role of symmetries in meta-generalisation. We show that a recent successful meta RL approach that meta-learns an objective for backpropagation-based learning exhibits certain symmetries (specifically the reuse of the learning rule, and invariance to input and output permutations) that are not present in typical black-box meta RL systems. We hypothesise that these symmetries can play an important role in meta-generalisation. Building off recent work in black-box supervised meta learning, we develop a black-box meta RL system that exhibits these same symmetries. We show through careful experimentation that incorporating these symmetries can lead to algorithms with a greater ability to generalise to unseen action & observation spaces, tasks, and environments.",30,Meta reinforcement learning RL attempts to discover new RL algorithms automatically from environment interaction In so called black box approaches the policy and the learning algorithm are jointly represented by a single neural network These methods are very flexible but they tend to underperform in terms of generalisation to new unseen environments In this paper we explore the role of symmetries in meta generalisation We show that a recent successful meta RL approach that meta learns an objective for backpropagation based learning exhibits certain symmetries specifically the reuse of the learning rule and invariance to input and output permutations that are not present in typical black box meta RL systems We hypothesise that these symmetries can play an important role in meta generalisation Building off recent work in black box supervised meta learning we develop a black box meta RL system that exhibits these same symmetries We show through careful experimentation that incorporating these symmetries can lead to algorithms with a greater ability to generalise to unseen action observation spaces tasks and environments
30,30,Meta Learning,Meta-Learning in Neural Networks: A Survey,http://arxiv.org/abs/2004.05439v2,"The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",31,The field of meta learning or learning to learn has seen a dramatic rise in interest in recent years Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm meta learning aims to improve the learning algorithm itself given the experience of multiple learning episodes This paradigm provides an opportunity to tackle many conventional challenges of deep learning including data and computation bottlenecks as well as generalization This survey describes the contemporary meta learning landscape We first discuss definitions of meta learning and position it with respect to related fields such as transfer learning and hyperparameter optimization We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta learning methods today We survey promising applications and successes of meta learning such as few shot learning and reinforcement learning Finally we discuss outstanding challenges and promising areas for future research
31,31,Meta Learning,Meta-Learning across Meta-Tasks for Few-Shot Learning,http://arxiv.org/abs/2002.04274v4,"Existing meta-learning based few-shot learning (FSL) methods typically adopt an episodic training strategy whereby each episode contains a meta-task. Across episodes, these tasks are sampled randomly and their relationships are ignored. In this paper, we argue that the inter-meta-task relationships should be exploited and those tasks are sampled strategically to assist in meta-learning. Specifically, we consider the relationships defined over two types of meta-task pairs and propose different strategies to exploit them. (1) Two meta-tasks with disjoint sets of classes: this pair is interesting because it is reminiscent of the relationship between the source seen classes and target unseen classes, featured with domain gap caused by class differences. A novel learning objective termed meta-domain adaptation (MDA) is proposed to make the meta-learned model more robust to the domain gap. (2) Two meta-tasks with identical sets of classes: this pair is useful because it can be employed to learn models that are robust against poorly sampled few-shots. To that end, a novel meta-knowledge distillation (MKD) objective is formulated. There are some mistakes in the experiments. We thus choose to withdraw this paper.",32,Existing meta learning based few shot learning FSL methods typically adopt an episodic training strategy whereby each episode contains a meta task Across episodes these tasks are sampled randomly and their relationships are ignored In this paper we argue that the inter meta task relationships should be exploited and those tasks are sampled strategically to assist in meta learning Specifically we consider the relationships defined over two types of meta task pairs and propose different strategies to exploit them 0 Two meta tasks with disjoint sets of classes this pair is interesting because it is reminiscent of the relationship between the source seen classes and target unseen classes featured with domain gap caused by class differences A novel learning objective termed meta domain adaptation MDA is proposed to make the meta learned model more robust to the domain gap 0 Two meta tasks with identical sets of classes this pair is useful because it can be employed to learn models that are robust against poorly sampled few shots To that end a novel meta knowledge distillation MKD objective is formulated There are some mistakes in the experiments We thus choose to withdraw this paper
32,32,Meta Learning,ProMP: Proximal Meta-Policy Search,http://arxiv.org/abs/1810.06784v3,"Credit assignment in Meta-reinforcement learning (Meta-RL) is still poorly understood. Existing methods either neglect credit assignment to pre-adaptation behavior or implement it naively. This leads to poor sample-efficiency during meta-training as well as ineffective task identification strategies. This paper provides a theoretical analysis of credit assignment in gradient-based Meta-RL. Building on the gained insights we develop a novel meta-learning algorithm that overcomes both the issue of poor credit assignment and previous difficulties in estimating meta-policy gradients. By controlling the statistical distance of both pre-adaptation and adapted policies during meta-policy search, the proposed algorithm endows efficient and stable meta-learning. Our approach leads to superior pre-adaptation policy behavior and consistently outperforms previous Meta-RL algorithms in sample-efficiency, wall-clock time, and asymptotic performance.",33,Credit assignment in Meta reinforcement learning Meta RL is still poorly understood Existing methods either neglect credit assignment to pre adaptation behavior or implement it naively This leads to poor sample efficiency during meta training as well as ineffective task identification strategies This paper provides a theoretical analysis of credit assignment in gradient based Meta RL Building on the gained insights we develop a novel meta learning algorithm that overcomes both the issue of poor credit assignment and previous difficulties in estimating meta policy gradients By controlling the statistical distance of both pre adaptation and adapted policies during meta policy search the proposed algorithm endows efficient and stable meta learning Our approach leads to superior pre adaptation policy behavior and consistently outperforms previous Meta RL algorithms in sample efficiency wall clock time and asymptotic performance
33,33,Meta Learning,Characterizing classification datasets: a study of meta-features for meta-learning,http://arxiv.org/abs/1808.10406v2,"Meta-learning is increasingly used to support the recommendation of machine learning algorithms and their configurations. Such recommendations are made based on meta-data, consisting of performance evaluations of algorithms on prior datasets, as well as characterizations of these datasets. These characterizations, also called meta-features, describe properties of the data which are predictive for the performance of machine learning algorithms trained on them. Unfortunately, despite being used in a large number of studies, meta-features are not uniformly described, organized and computed, making many empirical studies irreproducible and hard to compare. This paper aims to deal with this by systematizing and standardizing data characterization measures for classification datasets used in meta-learning. Moreover, it presents MFE, a new tool for extracting meta-features from datasets and identifying more subtle reproducibility issues in the literature, proposing guidelines for data characterization that strengthen reproducible empirical research in meta-learning.",34,Meta learning is increasingly used to support the recommendation of machine learning algorithms and their configurations Such recommendations are made based on meta data consisting of performance evaluations of algorithms on prior datasets as well as characterizations of these datasets These characterizations also called meta features describe properties of the data which are predictive for the performance of machine learning algorithms trained on them Unfortunately despite being used in a large number of studies meta features are not uniformly described organized and computed making many empirical studies irreproducible and hard to compare This paper aims to deal with this by systematizing and standardizing data characterization measures for classification datasets used in meta learning Moreover it presents MFE a new tool for extracting meta features from datasets and identifying more subtle reproducibility issues in the literature proposing guidelines for data characterization that strengthen reproducible empirical research in meta learning
34,34,Meta Learning,Continuous Meta-Learning without Tasks,http://arxiv.org/abs/1912.08866v2,"Meta-learning is a promising strategy for learning to efficiently learn within new tasks, using data gathered from a distribution of tasks. However, the meta-learning literature thus far has focused on the task segmented setting, where at train-time, offline data is assumed to be split according to the underlying task, and at test-time, the algorithms are optimized to learn in a single task. In this work, we enable the application of generic meta-learning algorithms to settings where this task segmentation is unavailable, such as continual online learning with a time-varying task. We present meta-learning via online changepoint analysis (MOCA), an approach which augments a meta-learning algorithm with a differentiable Bayesian changepoint detection scheme. The framework allows both training and testing directly on time series data without segmenting it into discrete tasks. We demonstrate the utility of this approach on a nonlinear meta-regression benchmark as well as two meta-image-classification benchmarks.",35,Meta learning is a promising strategy for learning to efficiently learn within new tasks using data gathered from a distribution of tasks However the meta learning literature thus far has focused on the task segmented setting where at train time offline data is assumed to be split according to the underlying task and at test time the algorithms are optimized to learn in a single task In this work we enable the application of generic meta learning algorithms to settings where this task segmentation is unavailable such as continual online learning with a time varying task We present meta learning via online changepoint analysis MOCA an approach which augments a meta learning algorithm with a differentiable Bayesian changepoint detection scheme The framework allows both training and testing directly on time series data without segmenting it into discrete tasks We demonstrate the utility of this approach on a nonlinear meta regression benchmark as well as two meta image classification benchmarks
35,35,Meta Learning,Weighted Meta-Learning,http://arxiv.org/abs/2003.09465v1,"Meta-learning leverages related source tasks to learn an initialization that can be quickly fine-tuned to a target task with limited labeled examples. However, many popular meta-learning algorithms, such as model-agnostic meta-learning (MAML), only assume access to the target samples for fine-tuning. In this work, we provide a general framework for meta-learning based on weighting the loss of different source tasks, where the weights are allowed to depend on the target samples. In this general setting, we provide upper bounds on the distance of the weighted empirical risk of the source tasks and expected target risk in terms of an integral probability metric (IPM) and Rademacher complexity, which apply to a number of meta-learning settings including MAML and a weighted MAML variant. We then develop a learning algorithm based on minimizing the error bound with respect to an empirical IPM, including a weighted MAML algorithm, $\alpha$-MAML. Finally, we demonstrate empirically on several regression problems that our weighted meta-learning algorithm is able to find better initializations than uniformly-weighted meta-learning algorithms, such as MAML.",36,Meta learning leverages related source tasks to learn an initialization that can be quickly fine tuned to a target task with limited labeled examples However many popular meta learning algorithms such as model agnostic meta learning MAML only assume access to the target samples for fine tuning In this work we provide a general framework for meta learning based on weighting the loss of different source tasks where the weights are allowed to depend on the target samples In this general setting we provide upper bounds on the distance of the weighted empirical risk of the source tasks and expected target risk in terms of an integral probability metric IPM and Rademacher complexity which apply to a number of meta learning settings including MAML and a weighted MAML variant We then develop a learning algorithm based on minimizing the error bound with respect to an empirical IPM including a weighted MAML algorithm alpha MAML Finally we demonstrate empirically on several regression problems that our weighted meta learning algorithm is able to find better initializations than uniformly weighted meta learning algorithms such as MAML
36,36,Meta Learning,Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,http://arxiv.org/abs/2003.05334v2,"Off-Policy Actor-Critic (Off-PAC) methods have proven successful in a variety of continuous control tasks. Normally, the critic's action-value function is updated using temporal-difference, and the critic in turn provides a loss for the actor that trains it to take actions with higher expected return. In this paper, we introduce a novel and flexible meta-critic that observes the learning process and meta-learns an additional loss for the actor that accelerates and improves actor-critic learning. Compared to the vanilla critic, the meta-critic network is explicitly trained to accelerate the learning process; and compared to existing meta-learning algorithms, meta-critic is rapidly learned online for a single task, rather than slowly over a family of tasks. Crucially, our meta-critic framework is designed for off-policy based learners, which currently provide state-of-the-art reinforcement learning sample efficiency. We demonstrate that online meta-critic learning leads to improvements in avariety of continuous control environments when combined with contemporary Off-PAC methods DDPG, TD3 and the state-of-the-art SAC.",37,Off Policy Actor Critic Off PAC methods have proven successful in a variety of continuous control tasks Normally the critic s action value function is updated using temporal difference and the critic in turn provides a loss for the actor that trains it to take actions with higher expected return In this paper we introduce a novel and flexible meta critic that observes the learning process and meta learns an additional loss for the actor that accelerates and improves actor critic learning Compared to the vanilla critic the meta critic network is explicitly trained to accelerate the learning process and compared to existing meta learning algorithms meta critic is rapidly learned online for a single task rather than slowly over a family of tasks Crucially our meta critic framework is designed for off policy based learners which currently provide state of the art reinforcement learning sample efficiency We demonstrate that online meta critic learning leads to improvements in avariety of continuous control environments when combined with contemporary Off PAC methods DDPG TD 0 and the state of the art SAC
37,37,Meta Learning,learn2learn: A Library for Meta-Learning Research,http://arxiv.org/abs/2008.12284v2,"Meta-learning researchers face two fundamental issues in their empirical work: prototyping and reproducibility. Researchers are prone to make mistakes when prototyping new algorithms and tasks because modern meta-learning methods rely on unconventional functionalities of machine learning frameworks. In turn, reproducing existing results becomes a tedious endeavour -- a situation exacerbated by the lack of standardized implementations and benchmarks. As a result, researchers spend inordinate amounts of time on implementing software rather than understanding and developing new ideas.   This manuscript introduces learn2learn, a library for meta-learning research focused on solving those prototyping and reproducibility issues. learn2learn provides low-level routines common across a wide-range of meta-learning techniques (e.g. meta-descent, meta-reinforcement learning, few-shot learning), and builds standardized interfaces to algorithms and benchmarks on top of them. In releasing learn2learn under a free and open source license, we hope to foster a community around standardized software for meta-learning research.",38,Meta learning researchers face two fundamental issues in their empirical work prototyping and reproducibility Researchers are prone to make mistakes when prototyping new algorithms and tasks because modern meta learning methods rely on unconventional functionalities of machine learning frameworks In turn reproducing existing results becomes a tedious endeavour a situation exacerbated by the lack of standardized implementations and benchmarks As a result researchers spend inordinate amounts of time on implementing software rather than understanding and developing new ideas This manuscript introduces learn 0 learn a library for meta learning research focused on solving those prototyping and reproducibility issues learn 0 learn provides low level routines common across a wide range of meta learning techniques e g meta descent meta reinforcement learning few shot learning and builds standardized interfaces to algorithms and benchmarks on top of them In releasing learn 0 learn under a free and open source license we hope to foster a community around standardized software for meta learning research
38,38,Meta Learning,Modeling and Optimization Trade-off in Meta-learning,http://arxiv.org/abs/2010.12916v2,"By searching for shared inductive biases across tasks, meta-learning promises to accelerate learning on novel tasks, but with the cost of solving a complex bilevel optimization problem. We introduce and rigorously define the trade-off between accurate modeling and optimization ease in meta-learning. At one end, classic meta-learning algorithms account for the structure of meta-learning but solve a complex optimization problem, while at the other end domain randomized search (otherwise known as joint training) ignores the structure of meta-learning and solves a single level optimization problem. Taking MAML as the representative meta-learning algorithm, we theoretically characterize the trade-off for general non-convex risk functions as well as linear regression, for which we are able to provide explicit bounds on the errors associated with modeling and optimization. We also empirically study this trade-off for meta-reinforcement learning benchmarks.",39,By searching for shared inductive biases across tasks meta learning promises to accelerate learning on novel tasks but with the cost of solving a complex bilevel optimization problem We introduce and rigorously define the trade off between accurate modeling and optimization ease in meta learning At one end classic meta learning algorithms account for the structure of meta learning but solve a complex optimization problem while at the other end domain randomized search otherwise known as joint training ignores the structure of meta learning and solves a single level optimization problem Taking MAML as the representative meta learning algorithm we theoretically characterize the trade off for general non convex risk functions as well as linear regression for which we are able to provide explicit bounds on the errors associated with modeling and optimization We also empirically study this trade off for meta reinforcement learning benchmarks
39,39,Meta Learning,Information-Theoretic Generalization Bounds for Meta-Learning and Applications,http://arxiv.org/abs/2005.04372v4,"Meta-learning, or ""learning to learn"", refers to techniques that infer an inductive bias from data corresponding to multiple related tasks with the goal of improving the sample efficiency for new, previously unobserved, tasks. A key performance measure for meta-learning is the meta-generalization gap, that is, the difference between the average loss measured on the meta-training data and on a new, randomly selected task. This paper presents novel information-theoretic upper bounds on the meta-generalization gap. Two broad classes of meta-learning algorithms are considered that uses either separate within-task training and test sets, like MAML, or joint within-task training and test sets, like Reptile. Extending the existing work for conventional learning, an upper bound on the meta-generalization gap is derived for the former class that depends on the mutual information (MI) between the output of the meta-learning algorithm and its input meta-training data. For the latter, the derived bound includes an additional MI between the output of the per-task learning procedure and corresponding data set to capture within-task uncertainty. Tighter bounds are then developed, under given technical conditions, for the two classes via novel Individual Task MI (ITMI) bounds. Applications of the derived bounds are finally discussed, including a broad class of noisy iterative algorithms for meta-learning.",40,Meta learning or learning to learn refers to techniques that infer an inductive bias from data corresponding to multiple related tasks with the goal of improving the sample efficiency for new previously unobserved tasks A key performance measure for meta learning is the meta generalization gap that is the difference between the average loss measured on the meta training data and on a new randomly selected task This paper presents novel information theoretic upper bounds on the meta generalization gap Two broad classes of meta learning algorithms are considered that uses either separate within task training and test sets like MAML or joint within task training and test sets like Reptile Extending the existing work for conventional learning an upper bound on the meta generalization gap is derived for the former class that depends on the mutual information MI between the output of the meta learning algorithm and its input meta training data For the latter the derived bound includes an additional MI between the output of the per task learning procedure and corresponding data set to capture within task uncertainty Tighter bounds are then developed under given technical conditions for the two classes via novel Individual Task MI ITMI bounds Applications of the derived bounds are finally discussed including a broad class of noisy iterative algorithms for meta learning
40,40,Meta Learning,Task-similarity Aware Meta-learning through Nonparametric Kernel Regression,http://arxiv.org/abs/2006.07212v2,"This paper investigates the use of nonparametric kernel-regression to obtain a tasksimilarity aware meta-learning algorithm. Our hypothesis is that the use of tasksimilarity helps meta-learning when the available tasks are limited and may contain outlier/ dissimilar tasks. While existing meta-learning approaches implicitly assume the tasks as being similar, it is generally unclear how this task-similarity could be quantified and used in the learning. As a result, most popular metalearning approaches do not actively use the similarity/dissimilarity between the tasks, but rely on availability of huge number of tasks for their working. Our contribution is a novel framework for meta-learning that explicitly uses task-similarity in the form of kernels and an associated meta-learning algorithm. We model the task-specific parameters to belong to a reproducing kernel Hilbert space where the kernel function captures the similarity across tasks. The proposed algorithm iteratively learns a meta-parameter which is used to assign a task-specific descriptor for every task. The task descriptors are then used to quantify the task-similarity through the kernel function. We show how our approach conceptually generalizes the popular meta-learning approaches of model-agnostic meta-learning (MAML) and Meta-stochastic gradient descent (Meta-SGD) approaches. Numerical experiments with regression tasks show that our algorithm outperforms these approaches when the number of tasks is limited, even in the presence of outlier or dissimilar tasks. This supports our hypothesis that task-similarity helps improve the metalearning performance in task-limited and adverse settings.",41,This paper investigates the use of nonparametric kernel regression to obtain a tasksimilarity aware meta learning algorithm Our hypothesis is that the use of tasksimilarity helps meta learning when the available tasks are limited and may contain outlier dissimilar tasks While existing meta learning approaches implicitly assume the tasks as being similar it is generally unclear how this task similarity could be quantified and used in the learning As a result most popular metalearning approaches do not actively use the similarity dissimilarity between the tasks but rely on availability of huge number of tasks for their working Our contribution is a novel framework for meta learning that explicitly uses task similarity in the form of kernels and an associated meta learning algorithm We model the task specific parameters to belong to a reproducing kernel Hilbert space where the kernel function captures the similarity across tasks The proposed algorithm iteratively learns a meta parameter which is used to assign a task specific descriptor for every task The task descriptors are then used to quantify the task similarity through the kernel function We show how our approach conceptually generalizes the popular meta learning approaches of model agnostic meta learning MAML and Meta stochastic gradient descent Meta SGD approaches Numerical experiments with regression tasks show that our algorithm outperforms these approaches when the number of tasks is limited even in the presence of outlier or dissimilar tasks This supports our hypothesis that task similarity helps improve the metalearning performance in task limited and adverse settings
41,41,Meta Learning,MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration,http://arxiv.org/abs/2006.08170v4,"Meta reinforcement learning (meta-RL) extracts knowledge from previous tasks and achieves fast adaptation to new tasks. Despite recent progress, efficient exploration in meta-RL remains a key challenge in sparse-reward tasks, as it requires quickly finding informative task-relevant experiences in both meta-training and adaptation. To address this challenge, we explicitly model an exploration policy learning problem for meta-RL, which is separated from exploitation policy learning, and introduce a novel empowerment-driven exploration objective, which aims to maximize information gain for task identification. We derive a corresponding intrinsic reward and develop a new off-policy meta-RL framework, which efficiently learns separate context-aware exploration and exploitation policies by sharing the knowledge of task inference. Experimental evaluation shows that our meta-RL method significantly outperforms state-of-the-art baselines on various sparse-reward MuJoCo locomotion tasks and more complex sparse-reward Meta-World tasks.",42,Meta reinforcement learning meta RL extracts knowledge from previous tasks and achieves fast adaptation to new tasks Despite recent progress efficient exploration in meta RL remains a key challenge in sparse reward tasks as it requires quickly finding informative task relevant experiences in both meta training and adaptation To address this challenge we explicitly model an exploration policy learning problem for meta RL which is separated from exploitation policy learning and introduce a novel empowerment driven exploration objective which aims to maximize information gain for task identification We derive a corresponding intrinsic reward and develop a new off policy meta RL framework which efficiently learns separate context aware exploration and exploitation policies by sharing the knowledge of task inference Experimental evaluation shows that our meta RL method significantly outperforms state of the art baselines on various sparse reward MuJoCo locomotion tasks and more complex sparse reward Meta World tasks
42,42,Meta Learning,Combining Domain-Specific Meta-Learners in the Parameter Space for Cross-Domain Few-Shot Classification,http://arxiv.org/abs/2011.00179v1,"The goal of few-shot classification is to learn a model that can classify novel classes using only a few training examples. Despite the promising results shown by existing meta-learning algorithms in solving the few-shot classification problem, there still remains an important challenge: how to generalize to unseen domains while meta-learning on multiple seen domains? In this paper, we propose an optimization-based meta-learning method, called Combining Domain-Specific Meta-Learners (CosML), that addresses the cross-domain few-shot classification problem. CosML first trains a set of meta-learners, one for each training domain, to learn prior knowledge (i.e., meta-parameters) specific to each domain. The domain-specific meta-learners are then combined in the \emph{parameter space}, by taking a weighted average of their meta-parameters, which is used as the initialization parameters of a task network that is quickly adapted to novel few-shot classification tasks in an unseen domain. Our experiments show that CosML outperforms a range of state-of-the-art methods and achieves strong cross-domain generalization ability.",43,The goal of few shot classification is to learn a model that can classify novel classes using only a few training examples Despite the promising results shown by existing meta learning algorithms in solving the few shot classification problem there still remains an important challenge how to generalize to unseen domains while meta learning on multiple seen domains In this paper we propose an optimization based meta learning method called Combining Domain Specific Meta Learners CosML that addresses the cross domain few shot classification problem CosML first trains a set of meta learners one for each training domain to learn prior knowledge i e meta parameters specific to each domain The domain specific meta learners are then combined in the emph parameter space by taking a weighted average of their meta parameters which is used as the initialization parameters of a task network that is quickly adapted to novel few shot classification tasks in an unseen domain Our experiments show that CosML outperforms a range of state of the art methods and achieves strong cross domain generalization ability
43,43,Meta Learning,Meta-KD: A Meta Knowledge Distillation Framework for Language Model Compression across Domains,http://arxiv.org/abs/2012.01266v1,"Pre-trained language models have been applied to various NLP tasks with considerable performance gains. However, the large model sizes, together with the long inference time, limit the deployment of such models in real-time applications. Typical approaches consider knowledge distillation to distill large teacher models into small student models. However, most of these studies focus on single-domain only, which ignores the transferable knowledge from other domains. We argue that training a teacher with transferable knowledge digested across domains can achieve better generalization capability to help knowledge distillation. To this end, we propose a Meta-Knowledge Distillation (Meta-KD) framework to build a meta-teacher model that captures transferable knowledge across domains inspired by meta-learning and use it to pass knowledge to students. Specifically, we first leverage a cross-domain learning process to train the meta-teacher on multiple domains, and then propose a meta-distillation algorithm to learn single-domain student models with guidance from the meta-teacher. Experiments on two public multi-domain NLP tasks show the effectiveness and superiority of the proposed Meta-KD framework. We also demonstrate the capability of Meta-KD in both few-shot and zero-shot learning settings.",44,Pre trained language models have been applied to various NLP tasks with considerable performance gains However the large model sizes together with the long inference time limit the deployment of such models in real time applications Typical approaches consider knowledge distillation to distill large teacher models into small student models However most of these studies focus on single domain only which ignores the transferable knowledge from other domains We argue that training a teacher with transferable knowledge digested across domains can achieve better generalization capability to help knowledge distillation To this end we propose a Meta Knowledge Distillation Meta KD framework to build a meta teacher model that captures transferable knowledge across domains inspired by meta learning and use it to pass knowledge to students Specifically we first leverage a cross domain learning process to train the meta teacher on multiple domains and then propose a meta distillation algorithm to learn single domain student models with guidance from the meta teacher Experiments on two public multi domain NLP tasks show the effectiveness and superiority of the proposed Meta KD framework We also demonstrate the capability of Meta KD in both few shot and zero shot learning settings
44,44,Meta Learning,Joint Embedding of Meta-Path and Meta-Graph for Heterogeneous Information Networks,http://arxiv.org/abs/1809.04110v1,"Meta-graph is currently the most powerful tool for similarity search on heterogeneous information networks,where a meta-graph is a composition of meta-paths that captures the complex structural information. However, current relevance computing based on meta-graph only considers the complex structural information, but ignores its embedded meta-paths information. To address this problem, we proposeMEta-GrAph-based network embedding models, called MEGA and MEGA++, respectively. The MEGA model uses normalized relevance or similarity measures that are derived from a meta-graph and its embedded meta-paths between nodes simultaneously, and then leverages tensor decomposition method to perform node embedding. The MEGA++ further facilitates the use of coupled tensor-matrix decomposition method to obtain a joint embedding for nodes, which simultaneously considers the hidden relations of all meta information of a meta-graph.Extensive experiments on two real datasets demonstrate thatMEGA and MEGA++ are more effective than state-of-the-art approaches.",45,Meta graph is currently the most powerful tool for similarity search on heterogeneous information networks where a meta graph is a composition of meta paths that captures the complex structural information However current relevance computing based on meta graph only considers the complex structural information but ignores its embedded meta paths information To address this problem we proposeMEta GrAph based network embedding models called MEGA and MEGA respectively The MEGA model uses normalized relevance or similarity measures that are derived from a meta graph and its embedded meta paths between nodes simultaneously and then leverages tensor decomposition method to perform node embedding The MEGA further facilitates the use of coupled tensor matrix decomposition method to obtain a joint embedding for nodes which simultaneously considers the hidden relations of all meta information of a meta graph Extensive experiments on two real datasets demonstrate thatMEGA and MEGA are more effective than state of the art approaches
45,45,Meta Learning,Curriculum in Gradient-Based Meta-Reinforcement Learning,http://arxiv.org/abs/2002.07956v1,"Gradient-based meta-learners such as Model-Agnostic Meta-Learning (MAML) have shown strong few-shot performance in supervised and reinforcement learning settings. However, specifically in the case of meta-reinforcement learning (meta-RL), we can show that gradient-based meta-learners are sensitive to task distributions. With the wrong curriculum, agents suffer the effects of meta-overfitting, shallow adaptation, and adaptation instability. In this work, we begin by highlighting intriguing failure cases of gradient-based meta-RL and show that task distributions can wildly affect algorithmic outputs, stability, and performance. To address this problem, we leverage insights from recent literature on domain randomization and propose meta Active Domain Randomization (meta-ADR), which learns a curriculum of tasks for gradient-based meta-RL in a similar as ADR does for sim2real transfer. We show that this approach induces more stable policies on a variety of simulated locomotion and navigation tasks. We assess in- and out-of-distribution generalization and find that the learned task distributions, even in an unstructured task space, greatly improve the adaptation performance of MAML. Finally, we motivate the need for better benchmarking in meta-RL that prioritizes \textit{generalization} over single-task adaption performance.",46,Gradient based meta learners such as Model Agnostic Meta Learning MAML have shown strong few shot performance in supervised and reinforcement learning settings However specifically in the case of meta reinforcement learning meta RL we can show that gradient based meta learners are sensitive to task distributions With the wrong curriculum agents suffer the effects of meta overfitting shallow adaptation and adaptation instability In this work we begin by highlighting intriguing failure cases of gradient based meta RL and show that task distributions can wildly affect algorithmic outputs stability and performance To address this problem we leverage insights from recent literature on domain randomization and propose meta Active Domain Randomization meta ADR which learns a curriculum of tasks for gradient based meta RL in a similar as ADR does for sim 0 real transfer We show that this approach induces more stable policies on a variety of simulated locomotion and navigation tasks We assess in and out of distribution generalization and find that the learned task distributions even in an unstructured task space greatly improve the adaptation performance of MAML Finally we motivate the need for better benchmarking in meta RL that prioritizes textit generalization over single task adaption performance
46,46,Meta Learning,Guarantees for Tuning the Step Size using a Learning-to-Learn Approach,http://arxiv.org/abs/2006.16495v2,"Choosing the right parameters for optimization algorithms is often the key to their success in practice. Solving this problem using a learning-to-learn approach -- using meta-gradient descent on a meta-objective based on the trajectory that the optimizer generates -- was recently shown to be effective. However, the meta-optimization problem is difficult. In particular, the meta-gradient can often explode/vanish, and the learned optimizer may not have good generalization performance if the meta-objective is not chosen carefully. In this paper we give meta-optimization guarantees for the learning-to-learn approach on a simple problem of tuning the step size for quadratic loss. Our results show that the na\""ive objective suffers from meta-gradient explosion/vanishing problem. Although there is a way to design the meta-objective so that the meta-gradient remains polynomially bounded, computing the meta-gradient directly using backpropagation leads to numerical issues. We also characterize when it is necessary to compute the meta-objective on a separate validation set to ensure the generalization performance of the learned optimizer. Finally, we verify our results empirically and show that a similar phenomenon appears even for more complicated learned optimizers parametrized by neural networks.",47,Choosing the right parameters for optimization algorithms is often the key to their success in practice Solving this problem using a learning to learn approach using meta gradient descent on a meta objective based on the trajectory that the optimizer generates was recently shown to be effective However the meta optimization problem is difficult In particular the meta gradient can often explode vanish and the learned optimizer may not have good generalization performance if the meta objective is not chosen carefully In this paper we give meta optimization guarantees for the learning to learn approach on a simple problem of tuning the step size for quadratic loss Our results show that the na ive objective suffers from meta gradient explosion vanishing problem Although there is a way to design the meta objective so that the meta gradient remains polynomially bounded computing the meta gradient directly using backpropagation leads to numerical issues We also characterize when it is necessary to compute the meta objective on a separate validation set to ensure the generalization performance of the learned optimizer Finally we verify our results empirically and show that a similar phenomenon appears even for more complicated learned optimizers parametrized by neural networks
47,47,Meta Learning,Offline Meta-Reinforcement Learning with Online Self-Supervision,http://arxiv.org/abs/2107.03974v2,"Meta-reinforcement learning (RL) can meta-train policies that adapt to new tasks with orders of magnitude less data than standard RL, but meta-training itself is costly and time-consuming. If we can meta-train on offline data, then we can reuse the same static dataset, labeled once with rewards for different tasks, to meta-train policies that adapt to a variety of new tasks at meta-test time. Although this capability would make meta-RL a practical tool for real-world use, offline meta-RL presents additional challenges beyond online meta-RL or standard offline RL settings. Meta-RL learns an exploration strategy that collects data for adapting, and also meta-trains a policy that quickly adapts to data from a new task. Since this policy was meta-trained on a fixed, offline dataset, it might behave unpredictably when adapting to data collected by the learned exploration strategy, which differs systematically from the offline data and thus induces distributional shift. We do not want to remove this distributional shift by simply adopting a conservative exploration strategy, because learning an exploration strategy enables an agent to collect better data for faster adaptation. Instead, we propose a hybrid offline meta-RL algorithm, which uses offline data with rewards to meta-train an adaptive policy, and then collects additional unsupervised online data, without any reward labels to bridge this distribution shift. By not requiring reward labels for online collection, this data can be much cheaper to collect. We compare our method to prior work on offline meta-RL on simulated robot locomotion and manipulation tasks and find that using additional unsupervised online data collection leads to a dramatic improvement in the adaptive capabilities of the meta-trained policies, matching the performance of fully online meta-RL on a range of challenging domains that require generalization to new tasks.",48,Meta reinforcement learning RL can meta train policies that adapt to new tasks with orders of magnitude less data than standard RL but meta training itself is costly and time consuming If we can meta train on offline data then we can reuse the same static dataset labeled once with rewards for different tasks to meta train policies that adapt to a variety of new tasks at meta test time Although this capability would make meta RL a practical tool for real world use offline meta RL presents additional challenges beyond online meta RL or standard offline RL settings Meta RL learns an exploration strategy that collects data for adapting and also meta trains a policy that quickly adapts to data from a new task Since this policy was meta trained on a fixed offline dataset it might behave unpredictably when adapting to data collected by the learned exploration strategy which differs systematically from the offline data and thus induces distributional shift We do not want to remove this distributional shift by simply adopting a conservative exploration strategy because learning an exploration strategy enables an agent to collect better data for faster adaptation Instead we propose a hybrid offline meta RL algorithm which uses offline data with rewards to meta train an adaptive policy and then collects additional unsupervised online data without any reward labels to bridge this distribution shift By not requiring reward labels for online collection this data can be much cheaper to collect We compare our method to prior work on offline meta RL on simulated robot locomotion and manipulation tasks and find that using additional unsupervised online data collection leads to a dramatic improvement in the adaptive capabilities of the meta trained policies matching the performance of fully online meta RL on a range of challenging domains that require generalization to new tasks
48,48,Meta Learning,Bayesian Model-Agnostic Meta-Learning,http://arxiv.org/abs/1806.03836v4,"Learning to infer Bayesian posterior from a few-shot dataset is an important step towards robust meta-learning due to the model uncertainty inherent in the problem. In this paper, we propose a novel Bayesian model-agnostic meta-learning method. The proposed method combines scalable gradient-based meta-learning with nonparametric variational inference in a principled probabilistic framework. During fast adaptation, the method is capable of learning complex uncertainty structure beyond a point estimate or a simple Gaussian approximation. In addition, a robust Bayesian meta-update mechanism with a new meta-loss prevents overfitting during meta-update. Remaining an efficient gradient-based meta-learner, the method is also model-agnostic and simple to implement. Experiment results show the accuracy and robustness of the proposed method in various tasks: sinusoidal regression, image classification, active learning, and reinforcement learning.",49,Learning to infer Bayesian posterior from a few shot dataset is an important step towards robust meta learning due to the model uncertainty inherent in the problem In this paper we propose a novel Bayesian model agnostic meta learning method The proposed method combines scalable gradient based meta learning with nonparametric variational inference in a principled probabilistic framework During fast adaptation the method is capable of learning complex uncertainty structure beyond a point estimate or a simple Gaussian approximation In addition a robust Bayesian meta update mechanism with a new meta loss prevents overfitting during meta update Remaining an efficient gradient based meta learner the method is also model agnostic and simple to implement Experiment results show the accuracy and robustness of the proposed method in various tasks sinusoidal regression image classification active learning and reinforcement learning
49,49,Meta Learning,The effects of negative adaptation in Model-Agnostic Meta-Learning,http://arxiv.org/abs/1812.02159v1,"The capacity of meta-learning algorithms to quickly adapt to a variety of tasks, including ones they did not experience during meta-training, has been a key factor in the recent success of these methods on few-shot learning problems. This particular advantage of using meta-learning over standard supervised or reinforcement learning is only well founded under the assumption that the adaptation phase does improve the performance of our model on the task of interest. However, in the classical framework of meta-learning, this constraint is only mildly enforced, if not at all, and we only see an improvement on average over a distribution of tasks. In this paper, we show that the adaptation in an algorithm like MAML can significantly decrease the performance of an agent in a meta-reinforcement learning setting, even on a range of meta-training tasks.",50,The capacity of meta learning algorithms to quickly adapt to a variety of tasks including ones they did not experience during meta training has been a key factor in the recent success of these methods on few shot learning problems This particular advantage of using meta learning over standard supervised or reinforcement learning is only well founded under the assumption that the adaptation phase does improve the performance of our model on the task of interest However in the classical framework of meta learning this constraint is only mildly enforced if not at all and we only see an improvement on average over a distribution of tasks In this paper we show that the adaptation in an algorithm like MAML can significantly decrease the performance of an agent in a meta reinforcement learning setting even on a range of meta training tasks
50,50,Meta Learning,Hierarchical Meta Learning,http://arxiv.org/abs/1904.09081v1,"Meta learning is a promising solution to few-shot learning problems. However, existing meta learning methods are restricted to the scenarios where training and application tasks share the same out-put structure. To obtain a meta model applicable to the tasks with new structures, it is required to collect new training data and repeat the time-consuming meta training procedure. This makes them inefficient or even inapplicable in learning to solve heterogeneous few-shot learning tasks. We thus develop a novel and principled HierarchicalMeta Learning (HML) method. Different from existing methods that only focus on optimizing the adaptability of a meta model to similar tasks, HML also explicitly optimizes its generalizability across heterogeneous tasks. To this end, HML first factorizes a set of similar training tasks into heterogeneous ones and trains the meta model over them at two levels to maximize adaptation and generalization performance respectively. The resultant model can then directly generalize to new tasks. Extensive experiments on few-shot classification and regression problems clearly demonstrate the superiority of HML over fine-tuning and state-of-the-art meta learning approaches in terms of generalization across heterogeneous tasks.",51,Meta learning is a promising solution to few shot learning problems However existing meta learning methods are restricted to the scenarios where training and application tasks share the same out put structure To obtain a meta model applicable to the tasks with new structures it is required to collect new training data and repeat the time consuming meta training procedure This makes them inefficient or even inapplicable in learning to solve heterogeneous few shot learning tasks We thus develop a novel and principled HierarchicalMeta Learning HML method Different from existing methods that only focus on optimizing the adaptability of a meta model to similar tasks HML also explicitly optimizes its generalizability across heterogeneous tasks To this end HML first factorizes a set of similar training tasks into heterogeneous ones and trains the meta model over them at two levels to maximize adaptation and generalization performance respectively The resultant model can then directly generalize to new tasks Extensive experiments on few shot classification and regression problems clearly demonstrate the superiority of HML over fine tuning and state of the art meta learning approaches in terms of generalization across heterogeneous tasks
51,51,Meta Learning,Structured Prediction for Conditional Meta-Learning,http://arxiv.org/abs/2002.08799v2,"The goal of optimization-based meta-learning is to find a single initialization shared across a distribution of tasks to speed up the process of learning new tasks. Conditional meta-learning seeks task-specific initialization to better capture complex task distributions and improve performance. However, many existing conditional methods are difficult to generalize and lack theoretical guarantees. In this work, we propose a new perspective on conditional meta-learning via structured prediction. We derive task-adaptive structured meta-learning (TASML), a principled framework that yields task-specific objective functions by weighing meta-training data on target tasks. Our non-parametric approach is model-agnostic and can be combined with existing meta-learning methods to achieve conditioning. Empirically, we show that TASML improves the performance of existing meta-learning models, and outperforms the state-of-the-art on benchmark datasets.",52,The goal of optimization based meta learning is to find a single initialization shared across a distribution of tasks to speed up the process of learning new tasks Conditional meta learning seeks task specific initialization to better capture complex task distributions and improve performance However many existing conditional methods are difficult to generalize and lack theoretical guarantees In this work we propose a new perspective on conditional meta learning via structured prediction We derive task adaptive structured meta learning TASML a principled framework that yields task specific objective functions by weighing meta training data on target tasks Our non parametric approach is model agnostic and can be combined with existing meta learning methods to achieve conditioning Empirically we show that TASML improves the performance of existing meta learning models and outperforms the state of the art on benchmark datasets
52,52,Meta Learning,Learning Abstract Task Representations,http://arxiv.org/abs/2101.07852v3,"A proper form of data characterization can guide the process of learning-algorithm selection and model-performance estimation. The field of meta-learning has provided a rich body of work describing effective forms of data characterization using different families of meta-features (statistical, model-based, information-theoretic, topological, etc.). In this paper, we start with the abundant set of existing meta-features and propose a method to induce new abstract meta-features as latent variables in a deep neural network. We discuss the pitfalls of using traditional meta-features directly and argue for the importance of learning high-level task properties. We demonstrate our methodology using a deep neural network as a feature extractor. We demonstrate that 1) induced meta-models mapping abstract meta-features to generalization performance outperform other methods by ~18% on average, and 2) abstract meta-features attain high feature-relevance scores.",53,A proper form of data characterization can guide the process of learning algorithm selection and model performance estimation The field of meta learning has provided a rich body of work describing effective forms of data characterization using different families of meta features statistical model based information theoretic topological etc In this paper we start with the abundant set of existing meta features and propose a method to induce new abstract meta features as latent variables in a deep neural network We discuss the pitfalls of using traditional meta features directly and argue for the importance of learning high level task properties We demonstrate our methodology using a deep neural network as a feature extractor We demonstrate that 0 induced meta models mapping abstract meta features to generalization performance outperform other methods by 0 on average and 0 abstract meta features attain high feature relevance scores
53,53,Meta Learning,Transfer Bayesian Meta-learning via Weighted Free Energy Minimization,http://arxiv.org/abs/2106.10711v2,"Meta-learning optimizes the hyperparameters of a training procedure, such as its initialization, kernel, or learning rate, based on data sampled from a number of auxiliary tasks. A key underlying assumption is that the auxiliary tasks, known as meta-training tasks, share the same generating distribution as the tasks to be encountered at deployment time, known as meta-test tasks. This may, however, not be the case when the test environment differ from the meta-training conditions. To address shifts in task generating distribution between meta-training and meta-testing phases, this paper introduces weighted free energy minimization (WFEM) for transfer meta-learning. We instantiate the proposed approach for non-parametric Bayesian regression and classification via Gaussian Processes (GPs). The method is validated on a toy sinusoidal regression problem, as well as on classification using miniImagenet and CUB data sets, through comparison with standard meta-learning of GP priors as implemented by PACOH.",54,Meta learning optimizes the hyperparameters of a training procedure such as its initialization kernel or learning rate based on data sampled from a number of auxiliary tasks A key underlying assumption is that the auxiliary tasks known as meta training tasks share the same generating distribution as the tasks to be encountered at deployment time known as meta test tasks This may however not be the case when the test environment differ from the meta training conditions To address shifts in task generating distribution between meta training and meta testing phases this paper introduces weighted free energy minimization WFEM for transfer meta learning We instantiate the proposed approach for non parametric Bayesian regression and classification via Gaussian Processes GPs The method is validated on a toy sinusoidal regression problem as well as on classification using miniImagenet and CUB data sets through comparison with standard meta learning of GP priors as implemented by PACOH
54,54,Meta Learning,Frustratingly Easy Meta-Embedding -- Computing Meta-Embeddings by Averaging Source Word Embeddings,http://arxiv.org/abs/1804.05262v1,"Creating accurate meta-embeddings from pre-trained source embeddings has received attention lately. Methods based on global and locally-linear transformation and concatenation have shown to produce accurate meta-embeddings. In this paper, we show that the arithmetic mean of two distinct word embedding sets yields a performant meta-embedding that is comparable or better than more complex meta-embedding learning methods. The result seems counter-intuitive given that vector spaces in different source embeddings are not comparable and cannot be simply averaged. We give insight into why averaging can still produce accurate meta-embedding despite the incomparability of the source vector spaces.",55,Creating accurate meta embeddings from pre trained source embeddings has received attention lately Methods based on global and locally linear transformation and concatenation have shown to produce accurate meta embeddings In this paper we show that the arithmetic mean of two distinct word embedding sets yields a performant meta embedding that is comparable or better than more complex meta embedding learning methods The result seems counter intuitive given that vector spaces in different source embeddings are not comparable and cannot be simply averaged We give insight into why averaging can still produce accurate meta embedding despite the incomparability of the source vector spaces
55,55,Meta Learning,BOML: A Modularized Bilevel Optimization Library in Python for Meta Learning,http://arxiv.org/abs/2009.13357v1,"Meta-learning (a.k.a. learning to learn) has recently emerged as a promising paradigm for a variety of applications. There are now many meta-learning methods, each focusing on different modeling aspects of base and meta learners, but all can be (re)formulated as specific bilevel optimization problems. This work presents BOML, a modularized optimization library that unifies several meta-learning algorithms into a common bilevel optimization framework. It provides a hierarchical optimization pipeline together with a variety of iteration modules, which can be used to solve the mainstream categories of meta-learning methods, such as meta-feature-based and meta-initialization-based formulations. The library is written in Python and is available at https://github.com/dut-media-lab/BOML.",56,Meta learning a k a learning to learn has recently emerged as a promising paradigm for a variety of applications There are now many meta learning methods each focusing on different modeling aspects of base and meta learners but all can be re formulated as specific bilevel optimization problems This work presents BOML a modularized optimization library that unifies several meta learning algorithms into a common bilevel optimization framework It provides a hierarchical optimization pipeline together with a variety of iteration modules which can be used to solve the mainstream categories of meta learning methods such as meta feature based and meta initialization based formulations The library is written in Python and is available at https github com dut media lab BOML
56,56,Meta Learning,A Reweighted Meta Learning Framework for Robust Few Shot Learning,http://arxiv.org/abs/2011.06782v1,"Model-Agnostic Meta-Learning (MAML) is a popular gradient-based meta-learning framework that tries to find an optimal initialization to minimize the expected loss across all tasks during meta-training. However, it inherently assumes that the contribution of each instance/task to the meta-learner is equal. Therefore, it fails to address the problem of domain differences between base and novel classes in few-shot learning. In this work, we propose a novel and robust meta-learning algorithm, called RW-MAML, which learns to assign weights to training instances or tasks. We consider these weights to be hyper-parameters. Hence, we iteratively optimize the weights using a small set of validation tasks and an online approximation in a \emph{bi-bi-level} optimization framework, in contrast to the standard bi-level optimization in MAML. Therefore, we investigate a practical evaluation setting to demonstrate the scalability of our RW-MAML in two scenarios: (1) out-of-distribution tasks and (2) noisy labels in the meta-training stage. Extensive experiments on synthetic and real-world datasets demonstrate that our framework efficiently mitigates the effects of ""unwanted"" instances, showing that our proposed technique significantly outperforms state-of-the-art robust meta-learning methods.",57,Model Agnostic Meta Learning MAML is a popular gradient based meta learning framework that tries to find an optimal initialization to minimize the expected loss across all tasks during meta training However it inherently assumes that the contribution of each instance task to the meta learner is equal Therefore it fails to address the problem of domain differences between base and novel classes in few shot learning In this work we propose a novel and robust meta learning algorithm called RW MAML which learns to assign weights to training instances or tasks We consider these weights to be hyper parameters Hence we iteratively optimize the weights using a small set of validation tasks and an online approximation in a emph bi bi level optimization framework in contrast to the standard bi level optimization in MAML Therefore we investigate a practical evaluation setting to demonstrate the scalability of our RW MAML in two scenarios 0 out of distribution tasks and 0 noisy labels in the meta training stage Extensive experiments on synthetic and real world datasets demonstrate that our framework efficiently mitigates the effects of unwanted instances showing that our proposed technique significantly outperforms state of the art robust meta learning methods
57,57,Meta Learning,Meta-Learning with Fewer Tasks through Task Interpolation,http://arxiv.org/abs/2106.02695v1,"Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.",58,Meta learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge However the bottleneck of current meta learning algorithms is the requirement of a large number of meta training tasks which may not be accessible in real world scenarios To address the challenge that available tasks may not densely sample the space of tasks we propose to augment the task set through interpolation By meta learning with task interpolation MLTI our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels Under both gradient based and metric based meta learning settings our theoretical analysis shows MLTI corresponds to a data adaptive meta regularization and further improves the generalization Empirically in our experiments on eight datasets from diverse domains including image recognition pose prediction molecule property prediction and medical image classification we find that the proposed general MLTI framework is compatible with representative meta learning algorithms and consistently outperforms other state of the art strategies
58,58,Meta Learning,Meta-Learning-based Deep Reinforcement Learning for Multiobjective Optimization Problems,http://arxiv.org/abs/2105.02741v1,"Deep reinforcement learning (DRL) has recently shown its success in tackling complex combinatorial optimization problems. When these problems are extended to multiobjective ones, it becomes difficult for the existing DRL approaches to flexibly and efficiently deal with multiple subproblems determined by weight decomposition of objectives. This paper proposes a concise meta-learning-based DRL approach. It first trains a meta-model by meta-learning. The meta-model is fine-tuned with a few update steps to derive submodels for the corresponding subproblems. The Pareto front is built accordingly. The computational experiments on multiobjective traveling salesman problems demonstrate the superiority of our method over most of learning-based and iteration-based approaches.",59,Deep reinforcement learning DRL has recently shown its success in tackling complex combinatorial optimization problems When these problems are extended to multiobjective ones it becomes difficult for the existing DRL approaches to flexibly and efficiently deal with multiple subproblems determined by weight decomposition of objectives This paper proposes a concise meta learning based DRL approach It first trains a meta model by meta learning The meta model is fine tuned with a few update steps to derive submodels for the corresponding subproblems The Pareto front is built accordingly The computational experiments on multiobjective traveling salesman problems demonstrate the superiority of our method over most of learning based and iteration based approaches
59,59,Meta Learning,Meta-Learning Mean Functions for Gaussian Processes,http://arxiv.org/abs/1901.08098v4,"When fitting Bayesian machine learning models on scarce data, the main challenge is to obtain suitable prior knowledge and encode it into the model. Recent advances in meta-learning offer powerful methods for extracting such prior knowledge from data acquired in related tasks. When it comes to meta-learning in Gaussian process models, approaches in this setting have mostly focused on learning the kernel function of the prior, but not on learning its mean function. In this work, we explore meta-learning the mean function of a Gaussian process prior. We present analytical and empirical evidence that mean function learning can be useful in the meta-learning setting, discuss the risk of overfitting, and draw connections to other meta-learning approaches, such as model agnostic meta-learning and functional PCA.",60,When fitting Bayesian machine learning models on scarce data the main challenge is to obtain suitable prior knowledge and encode it into the model Recent advances in meta learning offer powerful methods for extracting such prior knowledge from data acquired in related tasks When it comes to meta learning in Gaussian process models approaches in this setting have mostly focused on learning the kernel function of the prior but not on learning its mean function In this work we explore meta learning the mean function of a Gaussian process prior We present analytical and empirical evidence that mean function learning can be useful in the meta learning setting discuss the risk of overfitting and draw connections to other meta learning approaches such as model agnostic meta learning and functional PCA
60,60,Meta Learning,Improving the Generalization of Meta-learning on Unseen Domains via Adversarial Shift,http://arxiv.org/abs/2107.11056v1,"Meta-learning provides a promising way for learning to efficiently learn and achieves great success in many applications. However, most meta-learning literature focuses on dealing with tasks from a same domain, making it brittle to generalize to tasks from the other unseen domains. In this work, we address this problem by simulating tasks from the other unseen domains to improve the generalization and robustness of meta-learning method. Specifically, we propose a model-agnostic shift layer to learn how to simulate the domain shift and generate pseudo tasks, and develop a new adversarial learning-to-learn mechanism to train it. Based on the pseudo tasks, the meta-learning model can learn cross-domain meta-knowledge, which can generalize well on unseen domains. We conduct extensive experiments under the domain generalization setting. Experimental results demonstrate that the proposed shift layer is applicable to various meta-learning frameworks. Moreover, our method also leads to state-of-the-art performance on different cross-domain few-shot classification benchmarks and produces good results on cross-domain few-shot regression.",61,Meta learning provides a promising way for learning to efficiently learn and achieves great success in many applications However most meta learning literature focuses on dealing with tasks from a same domain making it brittle to generalize to tasks from the other unseen domains In this work we address this problem by simulating tasks from the other unseen domains to improve the generalization and robustness of meta learning method Specifically we propose a model agnostic shift layer to learn how to simulate the domain shift and generate pseudo tasks and develop a new adversarial learning to learn mechanism to train it Based on the pseudo tasks the meta learning model can learn cross domain meta knowledge which can generalize well on unseen domains We conduct extensive experiments under the domain generalization setting Experimental results demonstrate that the proposed shift layer is applicable to various meta learning frameworks Moreover our method also leads to state of the art performance on different cross domain few shot classification benchmarks and produces good results on cross domain few shot regression
61,61,Meta Learning,Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems,http://arxiv.org/abs/1905.05644v1,"Natural language generation (NLG) is an essential component of task-oriented dialogue systems. Despite the recent success of neural approaches for NLG, they are typically developed for particular domains with rich annotated training examples. In this paper, we study NLG in a low-resource setting to generate sentences in new scenarios with handful training examples. We formulate the problem from a meta-learning perspective, and propose a generalized optimization-based approach (Meta-NLG) based on the well-recognized model-agnostic meta-learning (MAML) algorithm. Meta-NLG defines a set of meta tasks, and directly incorporates the objective of adapting to new low-resource NLG tasks into the meta-learning optimization process. Extensive experiments are conducted on a large multi-domain dataset (MultiWoz) with diverse linguistic variations. We show that Meta-NLG significantly outperforms other training procedures in various low-resource configurations. We analyze the results, and demonstrate that Meta-NLG adapts extremely fast and well to low-resource situations.",62,Natural language generation NLG is an essential component of task oriented dialogue systems Despite the recent success of neural approaches for NLG they are typically developed for particular domains with rich annotated training examples In this paper we study NLG in a low resource setting to generate sentences in new scenarios with handful training examples We formulate the problem from a meta learning perspective and propose a generalized optimization based approach Meta NLG based on the well recognized model agnostic meta learning MAML algorithm Meta NLG defines a set of meta tasks and directly incorporates the objective of adapting to new low resource NLG tasks into the meta learning optimization process Extensive experiments are conducted on a large multi domain dataset MultiWoz with diverse linguistic variations We show that Meta NLG significantly outperforms other training procedures in various low resource configurations We analyze the results and demonstrate that Meta NLG adapts extremely fast and well to low resource situations
62,62,Meta Learning,Meta-Learning for Few-Shot NMT Adaptation,http://arxiv.org/abs/2004.02745v1,"We present META-MT, a meta-learning approach to adapt Neural Machine Translation (NMT) systems in a few-shot setting. META-MT provides a new approach to make NMT models easily adaptable to many target domains with the minimal amount of in-domain data. We frame the adaptation of NMT systems as a meta-learning problem, where we learn to adapt to new unseen domains based on simulated offline meta-training domain adaptation tasks. We evaluate the proposed meta-learning strategy on ten domains with general large scale NMT systems. We show that META-MT significantly outperforms classical domain adaptation when very few in-domain examples are available. Our experiments shows that META-MT can outperform classical fine-tuning by up to 2.5 BLEU points after seeing only 4, 000 translated words (300 parallel sentences).",63,We present META MT a meta learning approach to adapt Neural Machine Translation NMT systems in a few shot setting META MT provides a new approach to make NMT models easily adaptable to many target domains with the minimal amount of in domain data We frame the adaptation of NMT systems as a meta learning problem where we learn to adapt to new unseen domains based on simulated offline meta training domain adaptation tasks We evaluate the proposed meta learning strategy on ten domains with general large scale NMT systems We show that META MT significantly outperforms classical domain adaptation when very few in domain examples are available Our experiments shows that META MT can outperform classical fine tuning by up to 0 0 BLEU points after seeing only 0 0 translated words 0 parallel sentences
63,63,Meta Learning,MGHRL: Meta Goal-generation for Hierarchical Reinforcement Learning,http://arxiv.org/abs/1909.13607v4,"Most meta reinforcement learning (meta-RL) methods learn to adapt to new tasks by directly optimizing the parameters of policies over primitive action space. Such algorithms work well in tasks with relatively slight difference. However, when the task distribution becomes wider, it would be quite inefficient to directly learn such a meta-policy. In this paper, we propose a new meta-RL algorithm called Meta Goal-generation for Hierarchical RL (MGHRL). Instead of directly generating policies over primitive action space for new tasks, MGHRL learns to generate high-level meta strategies over subgoals given past experience and leaves the rest of how to achieve subgoals as independent RL subtasks. Our empirical results on several challenging simulated robotics environments show that our method enables more efficient and generalized meta-learning from past experience.",64,Most meta reinforcement learning meta RL methods learn to adapt to new tasks by directly optimizing the parameters of policies over primitive action space Such algorithms work well in tasks with relatively slight difference However when the task distribution becomes wider it would be quite inefficient to directly learn such a meta policy In this paper we propose a new meta RL algorithm called Meta Goal generation for Hierarchical RL MGHRL Instead of directly generating policies over primitive action space for new tasks MGHRL learns to generate high level meta strategies over subgoals given past experience and leaves the rest of how to achieve subgoals as independent RL subtasks Our empirical results on several challenging simulated robotics environments show that our method enables more efficient and generalized meta learning from past experience
64,64,Meta Learning,PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees,http://arxiv.org/abs/2002.05551v5,"Meta-learning can successfully acquire useful inductive biases from data. Yet, its generalization properties to unseen learning tasks are poorly understood. Particularly if the number of meta-training tasks is small, this raises concerns about overfitting. We provide a theoretical analysis using the PAC-Bayesian framework and derive novel generalization bounds for meta-learning. Using these bounds, we develop a class of PAC-optimal meta-learning algorithms with performance guarantees and a principled meta-level regularization. Unlike previous PAC-Bayesian meta-learners, our method results in a standard stochastic optimization problem which can be solved efficiently and scales well. When instantiating our PAC-optimal hyper-posterior (PACOH) with Gaussian processes and Bayesian Neural Networks as base learners, the resulting methods yield state-of-the-art performance, both in terms of predictive accuracy and the quality of uncertainty estimates. Thanks to their principled treatment of uncertainty, our meta-learners can also be successfully employed for sequential decision problems.",65,Meta learning can successfully acquire useful inductive biases from data Yet its generalization properties to unseen learning tasks are poorly understood Particularly if the number of meta training tasks is small this raises concerns about overfitting We provide a theoretical analysis using the PAC Bayesian framework and derive novel generalization bounds for meta learning Using these bounds we develop a class of PAC optimal meta learning algorithms with performance guarantees and a principled meta level regularization Unlike previous PAC Bayesian meta learners our method results in a standard stochastic optimization problem which can be solved efficiently and scales well When instantiating our PAC optimal hyper posterior PACOH with Gaussian processes and Bayesian Neural Networks as base learners the resulting methods yield state of the art performance both in terms of predictive accuracy and the quality of uncertainty estimates Thanks to their principled treatment of uncertainty our meta learners can also be successfully employed for sequential decision problems
65,65,Meta Learning,MetaDelta: A Meta-Learning System for Few-shot Image Classification,http://arxiv.org/abs/2102.10744v1,"Meta-learning aims at learning quickly on novel tasks with limited data by transferring generic experience learned from previous tasks. Naturally, few-shot learning has been one of the most popular applications for meta-learning. However, existing meta-learning algorithms rarely consider the time and resource efficiency or the generalization capacity for unknown datasets, which limits their applicability in real-world scenarios. In this paper, we propose MetaDelta, a novel practical meta-learning system for the few-shot image classification. MetaDelta consists of two core components: i) multiple meta-learners supervised by a central controller to ensure efficiency, and ii) a meta-ensemble module in charge of integrated inference and better generalization. In particular, each meta-learner in MetaDelta is composed of a unique pretrained encoder fine-tuned by batch training and parameter-free decoder used for prediction. MetaDelta ranks first in the final phase in the AAAI 2021 MetaDL Challenge\footnote{https://competitions.codalab.org/competitions/26638}, demonstrating the advantages of our proposed system. The codes are publicly available at https://github.com/Frozenmad/MetaDelta.",66,Meta learning aims at learning quickly on novel tasks with limited data by transferring generic experience learned from previous tasks Naturally few shot learning has been one of the most popular applications for meta learning However existing meta learning algorithms rarely consider the time and resource efficiency or the generalization capacity for unknown datasets which limits their applicability in real world scenarios In this paper we propose MetaDelta a novel practical meta learning system for the few shot image classification MetaDelta consists of two core components i multiple meta learners supervised by a central controller to ensure efficiency and ii a meta ensemble module in charge of integrated inference and better generalization In particular each meta learner in MetaDelta is composed of a unique pretrained encoder fine tuned by batch training and parameter free decoder used for prediction MetaDelta ranks first in the final phase in the AAAI 0 MetaDL Challenge footnote https competitions codalab org competitions 0 demonstrating the advantages of our proposed system The codes are publicly available at https github com Frozenmad MetaDelta
66,66,Meta Learning,Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace,http://arxiv.org/abs/1801.05558v3,"Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during meta-testing. Our primary contribution is the {\em MT-net}, which enables the meta-learner to learn on each layer's activation space a subspace that the task-specific learner performs gradient descent on. Additionally, a task-specific learner of an {\em MT-net} performs gradient descent with respect to a meta-learned distance metric, which warps the activation space to be more sensitive to task identity. We demonstrate that the dimension of this learned subspace reflects the complexity of the task-specific learner's adaptation task, and also that our model is less sensitive to the choice of initial learning rates than previous gradient-based meta-learning methods. Our method achieves state-of-the-art or comparable performance on few-shot classification and regression tasks.",67,Gradient based meta learning methods leverage gradient descent to learn the commonalities among various tasks While previous such methods have been successful in meta learning tasks they resort to simple gradient descent during meta testing Our primary contribution is the em MT net which enables the meta learner to learn on each layer s activation space a subspace that the task specific learner performs gradient descent on Additionally a task specific learner of an em MT net performs gradient descent with respect to a meta learned distance metric which warps the activation space to be more sensitive to task identity We demonstrate that the dimension of this learned subspace reflects the complexity of the task specific learner s adaptation task and also that our model is less sensitive to the choice of initial learning rates than previous gradient based meta learning methods Our method achieves state of the art or comparable performance on few shot classification and regression tasks
67,67,Meta Learning,Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning,http://arxiv.org/abs/2003.04390v4,"Meta-learning has been the most common framework for few-shot learning in recent years. It learns the model from collections of few-shot classification tasks, which is believed to have a key advantage of making the training objective consistent with the testing objective. However, some recent works report that by training for whole-classification, i.e. classification on the whole label-set, it can get comparable or even better embedding than many meta-learning algorithms. The edge between these two lines of works has yet been underexplored, and the effectiveness of meta-learning in few-shot learning remains unclear. In this paper, we explore a simple process: meta-learning over a whole-classification pre-trained model on its evaluation metric. We observe this simple method achieves competitive performance to state-of-the-art methods on standard benchmarks. Our further analysis shed some light on understanding the trade-offs between the meta-learning objective and the whole-classification objective in few-shot learning.",68,Meta learning has been the most common framework for few shot learning in recent years It learns the model from collections of few shot classification tasks which is believed to have a key advantage of making the training objective consistent with the testing objective However some recent works report that by training for whole classification i e classification on the whole label set it can get comparable or even better embedding than many meta learning algorithms The edge between these two lines of works has yet been underexplored and the effectiveness of meta learning in few shot learning remains unclear In this paper we explore a simple process meta learning over a whole classification pre trained model on its evaluation metric We observe this simple method achieves competitive performance to state of the art methods on standard benchmarks Our further analysis shed some light on understanding the trade offs between the meta learning objective and the whole classification objective in few shot learning
68,68,Meta Learning,Is Support Set Diversity Necessary for Meta-Learning?,http://arxiv.org/abs/2011.14048v1,"Meta-learning is a popular framework for learning with limited data in which an algorithm is produced by training over multiple few-shot learning tasks. For classification problems, these tasks are typically constructed by sampling a small number of support and query examples from a subset of the classes. While conventional wisdom is that task diversity should improve the performance of meta-learning, in this work we find evidence to the contrary: we propose a modification to traditional meta-learning approaches in which we keep the support sets fixed across tasks, thus reducing task diversity. Surprisingly, we find that not only does this modification not result in adverse effects, it almost always improves the performance for a variety of datasets and meta-learning methods. We also provide several initial analyses to understand this phenomenon. Our work serves to: (i) more closely investigate the effect of support set construction for the problem of meta-learning, and (ii) suggest a simple, general, and competitive baseline for few-shot learning.",69,Meta learning is a popular framework for learning with limited data in which an algorithm is produced by training over multiple few shot learning tasks For classification problems these tasks are typically constructed by sampling a small number of support and query examples from a subset of the classes While conventional wisdom is that task diversity should improve the performance of meta learning in this work we find evidence to the contrary we propose a modification to traditional meta learning approaches in which we keep the support sets fixed across tasks thus reducing task diversity Surprisingly we find that not only does this modification not result in adverse effects it almost always improves the performance for a variety of datasets and meta learning methods We also provide several initial analyses to understand this phenomenon Our work serves to i more closely investigate the effect of support set construction for the problem of meta learning and ii suggest a simple general and competitive baseline for few shot learning
69,69,Meta Learning,Meta Learning Backpropagation And Improving It,http://arxiv.org/abs/2012.14905v2,"Many concepts have been proposed for meta learning with neural networks (NNs), e.g., NNs that learn to control fast weights, hyper networks, learned learning rules, and meta recurrent NNs. Our Variable Shared Meta Learning (VS-ML) unifies the above and demonstrates that simple weight-sharing and sparsity in an NN is sufficient to express powerful learning algorithms (LAs) in a reusable fashion. A simple implementation of VS-ML called VS-ML RNN allows for implementing the backpropagation LA solely by running an RNN in forward-mode. It can even meta-learn new LAs that improve upon backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation. Introspection reveals that our meta-learned LAs learn qualitatively different from gradient descent through fast association.",70,Many concepts have been proposed for meta learning with neural networks NNs e g NNs that learn to control fast weights hyper networks learned learning rules and meta recurrent NNs Our Variable Shared Meta Learning VS ML unifies the above and demonstrates that simple weight sharing and sparsity in an NN is sufficient to express powerful learning algorithms LAs in a reusable fashion A simple implementation of VS ML called VS ML RNN allows for implementing the backpropagation LA solely by running an RNN in forward mode It can even meta learn new LAs that improve upon backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation Introspection reveals that our meta learned LAs learn qualitatively different from gradient descent through fast association
70,70,Meta Learning,Meta-QSAR: a large-scale application of meta-learning to drug design and discovery,http://arxiv.org/abs/1709.03854v1,"We investigate the learning of quantitative structure activity relationships (QSARs) as a case-study of meta-learning. This application area is of the highest societal importance, as it is a key step in the development of new medicines. The standard QSAR learning problem is: given a target (usually a protein) and a set of chemical compounds (small molecules) with associated bioactivities (e.g. inhibition of the target), learn a predictive mapping from molecular representation to activity. Although almost every type of machine learning method has been applied to QSAR learning there is no agreed single best way of learning QSARs, and therefore the problem area is well-suited to meta-learning. We first carried out the most comprehensive ever comparison of machine learning methods for QSAR learning: 18 regression methods, 6 molecular representations, applied to more than 2,700 QSAR problems. (These results have been made publicly available on OpenML and represent a valuable resource for testing novel meta-learning methods.) We then investigated the utility of algorithm selection for QSAR problems. We found that this meta-learning approach outperformed the best individual QSAR learning method (random forests using a molecular fingerprint representation) by up to 13%, on average. We conclude that meta-learning outperforms base-learning methods for QSAR learning, and as this investigation is one of the most extensive ever comparisons of base and meta-learning methods ever made, it provides evidence for the general effectiveness of meta-learning over base-learning.",71,We investigate the learning of quantitative structure activity relationships QSARs as a case study of meta learning This application area is of the highest societal importance as it is a key step in the development of new medicines The standard QSAR learning problem is given a target usually a protein and a set of chemical compounds small molecules with associated bioactivities e g inhibition of the target learn a predictive mapping from molecular representation to activity Although almost every type of machine learning method has been applied to QSAR learning there is no agreed single best way of learning QSARs and therefore the problem area is well suited to meta learning We first carried out the most comprehensive ever comparison of machine learning methods for QSAR learning 0 regression methods 0 molecular representations applied to more than 0 0 QSAR problems These results have been made publicly available on OpenML and represent a valuable resource for testing novel meta learning methods We then investigated the utility of algorithm selection for QSAR problems We found that this meta learning approach outperformed the best individual QSAR learning method random forests using a molecular fingerprint representation by up to 0 on average We conclude that meta learning outperforms base learning methods for QSAR learning and as this investigation is one of the most extensive ever comparisons of base and meta learning methods ever made it provides evidence for the general effectiveness of meta learning over base learning
71,71,Meta Learning,Unsupervised Curricula for Visual Meta-Reinforcement Learning,http://arxiv.org/abs/1912.04226v1,"In principle, meta-reinforcement learning algorithms leverage experience across many tasks to learn fast reinforcement learning (RL) strategies that transfer to similar tasks. However, current meta-RL approaches rely on manually-defined distributions of training tasks, and hand-crafting these task distributions can be challenging and time-consuming. Can ""useful"" pre-training tasks be discovered in an unsupervised manner? We develop an unsupervised algorithm for inducing an adaptive meta-training task distribution, i.e. an automatic curriculum, by modeling unsupervised interaction in a visual environment. The task distribution is scaffolded by a parametric density model of the meta-learner's trajectory distribution. We formulate unsupervised meta-RL as information maximization between a latent task variable and the meta-learner's data distribution, and describe a practical instantiation which alternates between integration of recent experience into the task distribution and meta-learning of the updated tasks. Repeating this procedure leads to iterative reorganization such that the curriculum adapts as the meta-learner's data distribution shifts. In particular, we show how discriminative clustering for visual representation can support trajectory-level task acquisition and exploration in domains with pixel observations, avoiding pitfalls of alternatives. In experiments on vision-based navigation and manipulation domains, we show that the algorithm allows for unsupervised meta-learning that transfers to downstream tasks specified by hand-crafted reward functions and serves as pre-training for more efficient supervised meta-learning of test task distributions.",72,In principle meta reinforcement learning algorithms leverage experience across many tasks to learn fast reinforcement learning RL strategies that transfer to similar tasks However current meta RL approaches rely on manually defined distributions of training tasks and hand crafting these task distributions can be challenging and time consuming Can useful pre training tasks be discovered in an unsupervised manner We develop an unsupervised algorithm for inducing an adaptive meta training task distribution i e an automatic curriculum by modeling unsupervised interaction in a visual environment The task distribution is scaffolded by a parametric density model of the meta learner s trajectory distribution We formulate unsupervised meta RL as information maximization between a latent task variable and the meta learner s data distribution and describe a practical instantiation which alternates between integration of recent experience into the task distribution and meta learning of the updated tasks Repeating this procedure leads to iterative reorganization such that the curriculum adapts as the meta learner s data distribution shifts In particular we show how discriminative clustering for visual representation can support trajectory level task acquisition and exploration in domains with pixel observations avoiding pitfalls of alternatives In experiments on vision based navigation and manipulation domains we show that the algorithm allows for unsupervised meta learning that transfers to downstream tasks specified by hand crafted reward functions and serves as pre training for more efficient supervised meta learning of test task distributions
72,72,Meta Learning,MELD: Meta-Reinforcement Learning from Images via Latent State Models,http://arxiv.org/abs/2010.13957v2,"Meta-reinforcement learning algorithms can enable autonomous agents, such as robots, to quickly acquire new behaviors by leveraging prior experience in a set of related training tasks. However, the onerous data requirements of meta-training compounded with the challenge of learning from sensory inputs such as images have made meta-RL challenging to apply to real robotic systems. Latent state models, which learn compact state representations from a sequence of observations, can accelerate representation learning from visual inputs. In this paper, we leverage the perspective of meta-learning as task inference to show that latent state models can \emph{also} perform meta-learning given an appropriately defined observation space. Building on this insight, we develop meta-RL with latent dynamics (MELD), an algorithm for meta-RL from images that performs inference in a latent state model to quickly acquire new skills given observations and rewards. MELD outperforms prior meta-RL methods on several simulated image-based robotic control problems, and enables a real WidowX robotic arm to insert an Ethernet cable into new locations given a sparse task completion signal after only $8$ hours of real world meta-training. To our knowledge, MELD is the first meta-RL algorithm trained in a real-world robotic control setting from images.",73,Meta reinforcement learning algorithms can enable autonomous agents such as robots to quickly acquire new behaviors by leveraging prior experience in a set of related training tasks However the onerous data requirements of meta training compounded with the challenge of learning from sensory inputs such as images have made meta RL challenging to apply to real robotic systems Latent state models which learn compact state representations from a sequence of observations can accelerate representation learning from visual inputs In this paper we leverage the perspective of meta learning as task inference to show that latent state models can emph also perform meta learning given an appropriately defined observation space Building on this insight we develop meta RL with latent dynamics MELD an algorithm for meta RL from images that performs inference in a latent state model to quickly acquire new skills given observations and rewards MELD outperforms prior meta RL methods on several simulated image based robotic control problems and enables a real WidowX robotic arm to insert an Ethernet cable into new locations given a sparse task completion signal after only 0 hours of real world meta training To our knowledge MELD is the first meta RL algorithm trained in a real world robotic control setting from images
73,73,Meta Learning,Revisiting Meta-Learning as Supervised Learning,http://arxiv.org/abs/2002.00573v1,"Recent years have witnessed an abundance of new publications and approaches on meta-learning. This community-wide enthusiasm has sparked great insights but has also created a plethora of seemingly different frameworks, which can be hard to compare and evaluate. In this paper, we aim to provide a principled, unifying framework by revisiting and strengthening the connection between meta-learning and traditional supervised learning. By treating pairs of task-specific data sets and target models as (feature, label) samples, we can reduce many meta-learning algorithms to instances of supervised learning. This view not only unifies meta-learning into an intuitive and practical framework but also allows us to transfer insights from supervised learning directly to improve meta-learning. For example, we obtain a better understanding of generalization properties, and we can readily transfer well-understood techniques, such as model ensemble, pre-training, joint training, data augmentation, and even nearest neighbor based methods. We provide an intuitive analogy of these methods in the context of meta-learning and show that they give rise to significant improvements in model performance on few-shot learning.",74,Recent years have witnessed an abundance of new publications and approaches on meta learning This community wide enthusiasm has sparked great insights but has also created a plethora of seemingly different frameworks which can be hard to compare and evaluate In this paper we aim to provide a principled unifying framework by revisiting and strengthening the connection between meta learning and traditional supervised learning By treating pairs of task specific data sets and target models as feature label samples we can reduce many meta learning algorithms to instances of supervised learning This view not only unifies meta learning into an intuitive and practical framework but also allows us to transfer insights from supervised learning directly to improve meta learning For example we obtain a better understanding of generalization properties and we can readily transfer well understood techniques such as model ensemble pre training joint training data augmentation and even nearest neighbor based methods We provide an intuitive analogy of these methods in the context of meta learning and show that they give rise to significant improvements in model performance on few shot learning
74,74,Meta Learning,Meta-Path Constrained Random Walk Inference for Large-Scale Heterogeneous Information Networks,http://arxiv.org/abs/1912.00634v1,"Heterogeneous information network (HIN) has shown its power of modeling real world data as a multi-typed entity-relation graph. Meta-path is the key contributor to this power since it enables inference by capturing the proximities between entities via rich semantic links. Previous HIN studies ask users to provide either 1) the meta-path(s) directly or 2) biased examples to generate the meta-path(s). However, lots of HINs (e.g., YAGO2 and Freebase) have rich schema consisting of a sophisticated and large number of types of entities and relations. It is impractical for users to provide the meta-path(s) to support the large scale inference, and biased examples will result in incorrect meta-path based inference, thus limit the power of the meta-path. In this paper, we propose a meta-path constrained inference framework to further release the ability of the meta-path, by efficiently learning the HIN inference patterns via a carefully designed tree structure; and performing unbiased random walk inference with little user guidance. The experiment results on YAGO2 and DBLP datasets show the state-of-the-art performance of the meta-path constrained inference framework.",75,Heterogeneous information network HIN has shown its power of modeling real world data as a multi typed entity relation graph Meta path is the key contributor to this power since it enables inference by capturing the proximities between entities via rich semantic links Previous HIN studies ask users to provide either 0 the meta path s directly or 0 biased examples to generate the meta path s However lots of HINs e g YAGO 0 and Freebase have rich schema consisting of a sophisticated and large number of types of entities and relations It is impractical for users to provide the meta path s to support the large scale inference and biased examples will result in incorrect meta path based inference thus limit the power of the meta path In this paper we propose a meta path constrained inference framework to further release the ability of the meta path by efficiently learning the HIN inference patterns via a carefully designed tree structure and performing unbiased random walk inference with little user guidance The experiment results on YAGO 0 and DBLP datasets show the state of the art performance of the meta path constrained inference framework
75,75,Meta Learning,Prior-Knowledge and Attention-based Meta-Learning for Few-Shot Learning,http://arxiv.org/abs/1812.04955v5,"Recently, meta-learning has been shown as a promising way to solve few-shot learning. In this paper, inspired by the human cognition process which utilizes both prior-knowledge and vision attention in learning new knowledge, we present a novel paradigm of meta-learning approach with three developments to introduce attention mechanism and prior-knowledge for meta-learning. In our approach, prior-knowledge is responsible for helping meta-learner expressing the input data into high-level representation space, and attention mechanism enables meta-learner focusing on key features of the data in the representation space. Compared with existing meta-learning approaches that pay little attention to prior-knowledge and vision attention, our approach alleviates the meta-learner's few-shot cognition burden. Furthermore, a Task-Over-Fitting (TOF) problem, which indicates that the meta-learner has poor generalization on different K-shot learning tasks, is discovered and we propose a Cross-Entropy across Tasks (CET) metric to model and solve the TOF problem. Extensive experiments demonstrate that we improve the meta-learner with state-of-the-art performance on several few-shot learning benchmarks, and at the same time the TOF problem can also be released greatly.",76,Recently meta learning has been shown as a promising way to solve few shot learning In this paper inspired by the human cognition process which utilizes both prior knowledge and vision attention in learning new knowledge we present a novel paradigm of meta learning approach with three developments to introduce attention mechanism and prior knowledge for meta learning In our approach prior knowledge is responsible for helping meta learner expressing the input data into high level representation space and attention mechanism enables meta learner focusing on key features of the data in the representation space Compared with existing meta learning approaches that pay little attention to prior knowledge and vision attention our approach alleviates the meta learner s few shot cognition burden Furthermore a Task Over Fitting TOF problem which indicates that the meta learner has poor generalization on different K shot learning tasks is discovered and we propose a Cross Entropy across Tasks CET metric to model and solve the TOF problem Extensive experiments demonstrate that we improve the meta learner with state of the art performance on several few shot learning benchmarks and at the same time the TOF problem can also be released greatly
76,76,Meta Learning,On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning,http://arxiv.org/abs/2102.10454v1,"Model-agnostic meta-learning (MAML) has emerged as one of the most successful meta-learning techniques in few-shot learning. It enables us to learn a meta-initialization} of model parameters (that we call meta-model) to rapidly adapt to new tasks using a small amount of labeled training data. Despite the generalization power of the meta-model, it remains elusive that how adversarial robustness can be maintained by MAML in few-shot learning. In addition to generalization, robustness is also desired for a meta-model to defend adversarial examples (attacks). Toward promoting adversarial robustness in MAML, we first study WHEN a robustness-promoting regularization should be incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs. meta-update) learning procedure. We show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons' activation maps. Furthermore, we investigate HOW robust regularization can efficiently be designed in MAML. We propose a general but easily-optimized robustness-regularized meta-learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine-tuning. In particular, we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML. Finally, extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few-shot learning.",77,Model agnostic meta learning MAML has emerged as one of the most successful meta learning techniques in few shot learning It enables us to learn a meta initialization of model parameters that we call meta model to rapidly adapt to new tasks using a small amount of labeled training data Despite the generalization power of the meta model it remains elusive that how adversarial robustness can be maintained by MAML in few shot learning In addition to generalization robustness is also desired for a meta model to defend adversarial examples attacks Toward promoting adversarial robustness in MAML we first study WHEN a robustness promoting regularization should be incorporated given the fact that MAML adopts a bi level fine tuning vs meta update learning procedure We show that robustifying the meta update stage is sufficient to make robustness adapted to the task specific fine tuning stage even if the latter uses a standard training protocol We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons activation maps Furthermore we investigate HOW robust regularization can efficiently be designed in MAML We propose a general but easily optimized robustness regularized meta learning framework which allows the use of unlabeled data augmentation fast adversarial attack generation and computationally light fine tuning In particular we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML Finally extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few shot learning
77,77,Meta Learning,Robustifying Sequential Neural Processes,http://arxiv.org/abs/2006.15987v1,"When tasks change over time, meta-transfer learning seeks to improve the efficiency of learning a new task via both meta-learning and transfer-learning. While the standard attention has been effective in a variety of settings, we question its effectiveness in improving meta-transfer learning since the tasks being learned are dynamic and the amount of context can be substantially smaller. In this paper, using a recently proposed meta-transfer learning model, Sequential Neural Processes (SNP), we first empirically show that it suffers from a similar underfitting problem observed in the functions inferred by Neural Processes. However, we further demonstrate that unlike the meta-learning setting, the standard attention mechanisms are not effective in meta-transfer setting. To resolve, we propose a new attention mechanism, Recurrent Memory Reconstruction (RMR), and demonstrate that providing an imaginary context that is recurrently updated and reconstructed with interaction is crucial in achieving effective attention for meta-transfer learning. Furthermore, incorporating RMR into SNP, we propose Attentive Sequential Neural Processes-RMR (ASNP-RMR) and demonstrate in various tasks that ASNP-RMR significantly outperforms the baselines.",78,When tasks change over time meta transfer learning seeks to improve the efficiency of learning a new task via both meta learning and transfer learning While the standard attention has been effective in a variety of settings we question its effectiveness in improving meta transfer learning since the tasks being learned are dynamic and the amount of context can be substantially smaller In this paper using a recently proposed meta transfer learning model Sequential Neural Processes SNP we first empirically show that it suffers from a similar underfitting problem observed in the functions inferred by Neural Processes However we further demonstrate that unlike the meta learning setting the standard attention mechanisms are not effective in meta transfer setting To resolve we propose a new attention mechanism Recurrent Memory Reconstruction RMR and demonstrate that providing an imaginary context that is recurrently updated and reconstructed with interaction is crucial in achieving effective attention for meta transfer learning Furthermore incorporating RMR into SNP we propose Attentive Sequential Neural Processes RMR ASNP RMR and demonstrate in various tasks that ASNP RMR significantly outperforms the baselines
78,78,Meta Learning,Provable Meta-Learning of Linear Representations,http://arxiv.org/abs/2002.11684v4,"Meta-learning, or learning-to-learn, seeks to design algorithms that can utilize previous experience to rapidly learn new skills or adapt to new environments. Representation learning -- a key tool for performing meta-learning -- learns a data representation that can transfer knowledge across multiple tasks, which is essential in regimes where data is scarce. Despite a recent surge of interest in the practice of meta-learning, the theoretical underpinnings of meta-learning algorithms are lacking, especially in the context of learning transferable representations. In this paper, we focus on the problem of multi-task linear regression -- in which multiple linear regression models share a common, low-dimensional linear representation. Here, we provide provably fast, sample-efficient algorithms to address the dual challenges of (1) learning a common set of features from multiple, related tasks, and (2) transferring this knowledge to new, unseen tasks. Both are central to the general problem of meta-learning. Finally, we complement these results by providing information-theoretic lower bounds on the sample complexity of learning these linear features.",79,Meta learning or learning to learn seeks to design algorithms that can utilize previous experience to rapidly learn new skills or adapt to new environments Representation learning a key tool for performing meta learning learns a data representation that can transfer knowledge across multiple tasks which is essential in regimes where data is scarce Despite a recent surge of interest in the practice of meta learning the theoretical underpinnings of meta learning algorithms are lacking especially in the context of learning transferable representations In this paper we focus on the problem of multi task linear regression in which multiple linear regression models share a common low dimensional linear representation Here we provide provably fast sample efficient algorithms to address the dual challenges of 0 learning a common set of features from multiple related tasks and 0 transferring this knowledge to new unseen tasks Both are central to the general problem of meta learning Finally we complement these results by providing information theoretic lower bounds on the sample complexity of learning these linear features
79,79,Meta Learning,Meta-GNN: On Few-shot Node Classification in Graph Meta-learning,http://arxiv.org/abs/1905.09718v1,"Meta-learning has received a tremendous recent attention as a possible approach for mimicking human intelligence, i.e., acquiring new knowledge and skills with little or even no demonstration. Most of the existing meta-learning methods are proposed to tackle few-shot learning problems such as image and text, in rather Euclidean domain. However, there are very few works applying meta-learning to non-Euclidean domains, and the recently proposed graph neural networks (GNNs) models do not perform effectively on graph few-shot learning problems. Towards this, we propose a novel graph meta-learning framework -- Meta-GNN -- to tackle the few-shot node classification problem in graph meta-learning settings. It obtains the prior knowledge of classifiers by training on many similar few-shot learning tasks and then classifies the nodes from new classes with only few labeled samples. Additionally, Meta-GNN is a general model that can be straightforwardly incorporated into any existing state-of-the-art GNN. Our experiments conducted on three benchmark datasets demonstrate that our proposed approach not only improves the node classification performance by a large margin on few-shot learning problems in meta-learning paradigm, but also learns a more general and flexible model for task adaption.",80,Meta learning has received a tremendous recent attention as a possible approach for mimicking human intelligence i e acquiring new knowledge and skills with little or even no demonstration Most of the existing meta learning methods are proposed to tackle few shot learning problems such as image and text in rather Euclidean domain However there are very few works applying meta learning to non Euclidean domains and the recently proposed graph neural networks GNNs models do not perform effectively on graph few shot learning problems Towards this we propose a novel graph meta learning framework Meta GNN to tackle the few shot node classification problem in graph meta learning settings It obtains the prior knowledge of classifiers by training on many similar few shot learning tasks and then classifies the nodes from new classes with only few labeled samples Additionally Meta GNN is a general model that can be straightforwardly incorporated into any existing state of the art GNN Our experiments conducted on three benchmark datasets demonstrate that our proposed approach not only improves the node classification performance by a large margin on few shot learning problems in meta learning paradigm but also learns a more general and flexible model for task adaption
80,80,Meta Learning,Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks,http://arxiv.org/abs/1905.12917v2,"While tasks could come with varying the number of instances and classes in realistic settings, the existing meta-learning approaches for few-shot classification assume that the number of instances per task and class is fixed. Due to such restriction, they learn to equally utilize the meta-knowledge across all the tasks, even when the number of instances per task and class largely varies. Moreover, they do not consider distributional difference in unseen tasks, on which the meta-knowledge may have less usefulness depending on the task relatedness. To overcome these limitations, we propose a novel meta-learning model that adaptively balances the effect of the meta-learning and task-specific learning within each task. Through the learning of the balancing variables, we can decide whether to obtain a solution by relying on the meta-knowledge or task-specific learning. We formulate this objective into a Bayesian inference framework and tackle it using variational inference. We validate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on multiple realistic task- and class-imbalanced datasets, on which it significantly outperforms existing meta-learning approaches. Further ablation study confirms the effectiveness of each balancing component and the Bayesian learning framework.",81,While tasks could come with varying the number of instances and classes in realistic settings the existing meta learning approaches for few shot classification assume that the number of instances per task and class is fixed Due to such restriction they learn to equally utilize the meta knowledge across all the tasks even when the number of instances per task and class largely varies Moreover they do not consider distributional difference in unseen tasks on which the meta knowledge may have less usefulness depending on the task relatedness To overcome these limitations we propose a novel meta learning model that adaptively balances the effect of the meta learning and task specific learning within each task Through the learning of the balancing variables we can decide whether to obtain a solution by relying on the meta knowledge or task specific learning We formulate this objective into a Bayesian inference framework and tackle it using variational inference We validate our Bayesian Task Adaptive Meta Learning Bayesian TAML on multiple realistic task and class imbalanced datasets on which it significantly outperforms existing meta learning approaches Further ablation study confirms the effectiveness of each balancing component and the Bayesian learning framework
81,81,Meta Learning,Adversarial Meta-Learning,http://arxiv.org/abs/1806.03316v3,"Meta-learning enables a model to learn from very limited data to undertake a new task. In this paper, we study the general meta-learning with adversarial samples. We present a meta-learning algorithm, ADML (ADversarial Meta-Learner), which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarial manner. ADML leads to the following desirable properties: 1) it turns out to be very effective even in the cases with only clean samples; 2) it is robust to adversarial samples, i.e., unlike other meta-learning algorithms, it only leads to a minor performance degradation when there are adversarial samples; 3) it sheds light on tackling the cases with limited and even contaminated samples. It has been shown by extensive experimental results that ADML consistently outperforms three representative meta-learning algorithms in the cases involving adversarial samples, on two widely-used image datasets, MiniImageNet and CIFAR100, in terms of both accuracy and robustness.",82,Meta learning enables a model to learn from very limited data to undertake a new task In this paper we study the general meta learning with adversarial samples We present a meta learning algorithm ADML ADversarial Meta Learner which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarial manner ADML leads to the following desirable properties 0 it turns out to be very effective even in the cases with only clean samples 0 it is robust to adversarial samples i e unlike other meta learning algorithms it only leads to a minor performance degradation when there are adversarial samples 0 it sheds light on tackling the cases with limited and even contaminated samples It has been shown by extensive experimental results that ADML consistently outperforms three representative meta learning algorithms in the cases involving adversarial samples on two widely used image datasets MiniImageNet and CIFAR 0 in terms of both accuracy and robustness
82,82,Meta Learning,Meta-Learning Initializations for Image Segmentation,http://arxiv.org/abs/1912.06290v4,"We extend first-order model agnostic meta-learning algorithms (including FOMAML and Reptile) to image segmentation, present a novel neural network architecture built for fast learning which we call EfficientLab, and leverage a formal definition of the test error of meta-learning algorithms to decrease error on out of distribution tasks. We show state of the art results on the FSS-1000 dataset by meta-training EfficientLab with FOMAML and using Bayesian optimization to infer the optimal test-time adaptation routine hyperparameters. We also construct a small benchmark dataset, FP-k, for the empirical study of how meta-learning systems perform in both few- and many-shot settings. On the FP-k dataset, we show that meta-learned initializations provide value for canonical few-shot image segmentation but their performance is quickly matched by conventional transfer learning with performance being equal beyond 10 labeled examples. Our code, meta-learned model, and the FP-k dataset are available at https://github.com/ml4ai/mliis .",83,We extend first order model agnostic meta learning algorithms including FOMAML and Reptile to image segmentation present a novel neural network architecture built for fast learning which we call EfficientLab and leverage a formal definition of the test error of meta learning algorithms to decrease error on out of distribution tasks We show state of the art results on the FSS 0 dataset by meta training EfficientLab with FOMAML and using Bayesian optimization to infer the optimal test time adaptation routine hyperparameters We also construct a small benchmark dataset FP k for the empirical study of how meta learning systems perform in both few and many shot settings On the FP k dataset we show that meta learned initializations provide value for canonical few shot image segmentation but their performance is quickly matched by conventional transfer learning with performance being equal beyond 0 labeled examples Our code meta learned model and the FP k dataset are available at https github com ml 0 ai mliis
83,83,Meta Learning,TaskNorm: Rethinking Batch Normalization for Meta-Learning,http://arxiv.org/abs/2003.03284v2,"Modern meta-learning approaches for image classification rely on increasingly deep networks to achieve state-of-the-art performance, making batch normalization an essential component of meta-learning pipelines. However, the hierarchical nature of the meta-learning setting presents several challenges that can render conventional batch normalization ineffective, giving rise to the need to rethink normalization in this setting. We evaluate a range of approaches to batch normalization for meta-learning scenarios, and develop a novel approach that we call TaskNorm. Experiments on fourteen datasets demonstrate that the choice of batch normalization has a dramatic effect on both classification accuracy and training time for both gradient based and gradient-free meta-learning approaches. Importantly, TaskNorm is found to consistently improve performance. Finally, we provide a set of best practices for normalization that will allow fair comparison of meta-learning algorithms.",84,Modern meta learning approaches for image classification rely on increasingly deep networks to achieve state of the art performance making batch normalization an essential component of meta learning pipelines However the hierarchical nature of the meta learning setting presents several challenges that can render conventional batch normalization ineffective giving rise to the need to rethink normalization in this setting We evaluate a range of approaches to batch normalization for meta learning scenarios and develop a novel approach that we call TaskNorm Experiments on fourteen datasets demonstrate that the choice of batch normalization has a dramatic effect on both classification accuracy and training time for both gradient based and gradient free meta learning approaches Importantly TaskNorm is found to consistently improve performance Finally we provide a set of best practices for normalization that will allow fair comparison of meta learning algorithms
84,84,Meta Learning,A contrastive rule for meta-learning,http://arxiv.org/abs/2104.01677v2,"Meta-learning algorithms leverage regularities that are present on a set of tasks to speed up and improve the performance of a subsidiary learning process. Recent work on deep neural networks has shown that prior gradient-based learning of meta-parameters can greatly improve the efficiency of subsequent learning. Here, we present a biologically plausible meta-learning algorithm based on equilibrium propagation. Instead of explicitly differentiating the learning process, our contrastive meta-learning rule estimates meta-parameter gradients by executing the subsidiary process more than once. This avoids reversing the learning dynamics in time and computing second-order derivatives. In spite of this, and unlike previous first-order methods, our rule recovers an arbitrarily accurate meta-parameter update given enough compute. We establish theoretical bounds on its performance and present experiments on a set of standard benchmarks and neural network architectures.",85,Meta learning algorithms leverage regularities that are present on a set of tasks to speed up and improve the performance of a subsidiary learning process Recent work on deep neural networks has shown that prior gradient based learning of meta parameters can greatly improve the efficiency of subsequent learning Here we present a biologically plausible meta learning algorithm based on equilibrium propagation Instead of explicitly differentiating the learning process our contrastive meta learning rule estimates meta parameter gradients by executing the subsidiary process more than once This avoids reversing the learning dynamics in time and computing second order derivatives In spite of this and unlike previous first order methods our rule recovers an arbitrarily accurate meta parameter update given enough compute We establish theoretical bounds on its performance and present experiments on a set of standard benchmarks and neural network architectures
85,85,Meta Learning,ST-MAML: A Stochastic-Task based Method for Task-Heterogeneous Meta-Learning,http://arxiv.org/abs/2109.13305v1,"Optimization-based meta-learning typically assumes tasks are sampled from a single distribution - an assumption oversimplifies and limits the diversity of tasks that meta-learning can model. Handling tasks from multiple different distributions is challenging for meta-learning due to a so-called task ambiguity issue. This paper proposes a novel method, ST-MAML, that empowers model-agnostic meta-learning (MAML) to learn from multiple task distributions. ST-MAML encodes tasks using a stochastic neural network module, that summarizes every task with a stochastic representation. The proposed Stochastic Task (ST) strategy allows a meta-model to get tailored for the current task and enables us to learn a distribution of solutions for an ambiguous task. ST-MAML also propagates the task representation to revise the encoding of input variables. Empirically, we demonstrate that ST-MAML matches or outperforms the state-of-the-art on two few-shot image classification tasks, one curve regression benchmark, one image completion problem, and a real-world temperature prediction application. To the best of authors' knowledge, this is the first time optimization-based meta-learning method being applied on a large-scale real-world task.",86,Optimization based meta learning typically assumes tasks are sampled from a single distribution an assumption oversimplifies and limits the diversity of tasks that meta learning can model Handling tasks from multiple different distributions is challenging for meta learning due to a so called task ambiguity issue This paper proposes a novel method ST MAML that empowers model agnostic meta learning MAML to learn from multiple task distributions ST MAML encodes tasks using a stochastic neural network module that summarizes every task with a stochastic representation The proposed Stochastic Task ST strategy allows a meta model to get tailored for the current task and enables us to learn a distribution of solutions for an ambiguous task ST MAML also propagates the task representation to revise the encoding of input variables Empirically we demonstrate that ST MAML matches or outperforms the state of the art on two few shot image classification tasks one curve regression benchmark one image completion problem and a real world temperature prediction application To the best of authors knowledge this is the first time optimization based meta learning method being applied on a large scale real world task
86,86,Meta Learning,The Advantage of Conditional Meta-Learning for Biased Regularization and Fine-Tuning,http://arxiv.org/abs/2008.10857v1,"Biased regularization and fine-tuning are two recent meta-learning approaches. They have been shown to be effective to tackle distributions of tasks, in which the tasks' target vectors are all close to a common meta-parameter vector. However, these methods may perform poorly on heterogeneous environments of tasks, where the complexity of the tasks' distribution cannot be captured by a single meta-parameter vector. We address this limitation by conditional meta-learning, inferring a conditioning function mapping task's side information into a meta-parameter vector that is appropriate for that task at hand. We characterize properties of the environment under which the conditional approach brings a substantial advantage over standard meta-learning and we highlight examples of environments, such as those with multiple clusters, satisfying these properties. We then propose a convex meta-algorithm providing a comparable advantage also in practice. Numerical experiments confirm our theoretical findings.",87,Biased regularization and fine tuning are two recent meta learning approaches They have been shown to be effective to tackle distributions of tasks in which the tasks target vectors are all close to a common meta parameter vector However these methods may perform poorly on heterogeneous environments of tasks where the complexity of the tasks distribution cannot be captured by a single meta parameter vector We address this limitation by conditional meta learning inferring a conditioning function mapping task s side information into a meta parameter vector that is appropriate for that task at hand We characterize properties of the environment under which the conditional approach brings a substantial advantage over standard meta learning and we highlight examples of environments such as those with multiple clusters satisfying these properties We then propose a convex meta algorithm providing a comparable advantage also in practice Numerical experiments confirm our theoretical findings
87,87,Meta Learning,Explaining the Performance of Multi-label Classification Methods with Data Set Properties,http://arxiv.org/abs/2106.15411v1,"Meta learning generalizes the empirical experience with different learning tasks and holds promise for providing important empirical insight into the behaviour of machine learning algorithms. In this paper, we present a comprehensive meta-learning study of data sets and methods for multi-label classification (MLC). MLC is a practically relevant machine learning task where each example is labelled with multiple labels simultaneously. Here, we analyze 40 MLC data sets by using 50 meta features describing different properties of the data. The main findings of this study are as follows. First, the most prominent meta features that describe the space of MLC data sets are the ones assessing different aspects of the label space. Second, the meta models show that the most important meta features describe the label space, and, the meta features describing the relationships among the labels tend to occur a bit more often than the meta features describing the distributions between and within the individual labels. Third, the optimization of the hyperparameters can improve the predictive performance, however, quite often the extent of the improvements does not always justify the resource utilization.",88,Meta learning generalizes the empirical experience with different learning tasks and holds promise for providing important empirical insight into the behaviour of machine learning algorithms In this paper we present a comprehensive meta learning study of data sets and methods for multi label classification MLC MLC is a practically relevant machine learning task where each example is labelled with multiple labels simultaneously Here we analyze 0 MLC data sets by using 0 meta features describing different properties of the data The main findings of this study are as follows First the most prominent meta features that describe the space of MLC data sets are the ones assessing different aspects of the label space Second the meta models show that the most important meta features describe the label space and the meta features describing the relationships among the labels tend to occur a bit more often than the meta features describing the distributions between and within the individual labels Third the optimization of the hyperparameters can improve the predictive performance however quite often the extent of the improvements does not always justify the resource utilization
88,88,Meta Learning,Weakly-supervised Graph Meta-learning for Few-shot Node Classification,http://arxiv.org/abs/2106.06873v1,"Graphs are widely used to model the relational structure of data, and the research of graph machine learning (ML) has a wide spectrum of applications ranging from drug design in molecular graphs to friendship recommendation in social networks. Prevailing approaches for graph ML typically require abundant labeled instances in achieving satisfactory results, which is commonly infeasible in real-world scenarios since labeled data for newly emerged concepts (e.g., new categorizations of nodes) on graphs is limited. Though meta-learning has been applied to different few-shot graph learning problems, most existing efforts predominately assume that all the data from those seen classes is gold-labeled, while those methods may lose their efficacy when the seen data is weakly-labeled with severe label noise. As such, we aim to investigate a novel problem of weakly-supervised graph meta-learning for improving the model robustness in terms of knowledge transfer. To achieve this goal, we propose a new graph meta-learning framework -- Graph Hallucination Networks (Meta-GHN) in this paper. Based on a new robustness-enhanced episodic training, Meta-GHN is meta-learned to hallucinate clean node representations from weakly-labeled data and extracts highly transferable meta-knowledge, which enables the model to quickly adapt to unseen tasks with few labeled instances. Extensive experiments demonstrate the superiority of Meta-GHN over existing graph meta-learning studies on the task of weakly-supervised few-shot node classification.",89,Graphs are widely used to model the relational structure of data and the research of graph machine learning ML has a wide spectrum of applications ranging from drug design in molecular graphs to friendship recommendation in social networks Prevailing approaches for graph ML typically require abundant labeled instances in achieving satisfactory results which is commonly infeasible in real world scenarios since labeled data for newly emerged concepts e g new categorizations of nodes on graphs is limited Though meta learning has been applied to different few shot graph learning problems most existing efforts predominately assume that all the data from those seen classes is gold labeled while those methods may lose their efficacy when the seen data is weakly labeled with severe label noise As such we aim to investigate a novel problem of weakly supervised graph meta learning for improving the model robustness in terms of knowledge transfer To achieve this goal we propose a new graph meta learning framework Graph Hallucination Networks Meta GHN in this paper Based on a new robustness enhanced episodic training Meta GHN is meta learned to hallucinate clean node representations from weakly labeled data and extracts highly transferable meta knowledge which enables the model to quickly adapt to unseen tasks with few labeled instances Extensive experiments demonstrate the superiority of Meta GHN over existing graph meta learning studies on the task of weakly supervised few shot node classification
89,89,Meta Learning,A Channel Coding Benchmark for Meta-Learning,http://arxiv.org/abs/2107.07579v2,"Meta-learning provides a popular and effective family of methods for data-efficient learning of new tasks. However, several important issues in meta-learning have proven hard to study thus far. For example, performance degrades in real-world settings where meta-learners must learn from a wide and potentially multi-modal distribution of training tasks; and when distribution shift exists between meta-train and meta-test task distributions. These issues are typically hard to study since the shape of task distributions, and shift between them are not straightforward to measure or control in standard benchmarks. We propose the channel coding problem as a benchmark for meta-learning. Channel coding is an important practical application where task distributions naturally arise, and fast adaptation to new tasks is practically valuable. We use our MetaCC benchmark to study several aspects of meta-learning, including the impact of task distribution breadth and shift, which can be controlled in the coding problem. Going forward, MetaCC provides a tool for the community to study the capabilities and limitations of meta-learning, and to drive research on practically robust and effective meta-learners.",90,Meta learning provides a popular and effective family of methods for data efficient learning of new tasks However several important issues in meta learning have proven hard to study thus far For example performance degrades in real world settings where meta learners must learn from a wide and potentially multi modal distribution of training tasks and when distribution shift exists between meta train and meta test task distributions These issues are typically hard to study since the shape of task distributions and shift between them are not straightforward to measure or control in standard benchmarks We propose the channel coding problem as a benchmark for meta learning Channel coding is an important practical application where task distributions naturally arise and fast adaptation to new tasks is practically valuable We use our MetaCC benchmark to study several aspects of meta learning including the impact of task distribution breadth and shift which can be controlled in the coding problem Going forward MetaCC provides a tool for the community to study the capabilities and limitations of meta learning and to drive research on practically robust and effective meta learners
90,90,Meta Learning,Learning Meta-Embeddings by Using Ensembles of Embedding Sets,http://arxiv.org/abs/1508.04257v2,"Word embeddings -- distributed representations of words -- in deep learning are beneficial for many tasks in natural language processing (NLP). However, different embedding sets vary greatly in quality and characteristics of the captured semantics. Instead of relying on a more advanced algorithm for embedding learning, this paper proposes an ensemble approach of combining different public embedding sets with the aim of learning meta-embeddings. Experiments on word similarity and analogy tasks and on part-of-speech tagging show better performance of meta-embeddings compared to individual embedding sets. One advantage of meta-embeddings is the increased vocabulary coverage. We will release our meta-embeddings publicly.",91,Word embeddings distributed representations of words in deep learning are beneficial for many tasks in natural language processing NLP However different embedding sets vary greatly in quality and characteristics of the captured semantics Instead of relying on a more advanced algorithm for embedding learning this paper proposes an ensemble approach of combining different public embedding sets with the aim of learning meta embeddings Experiments on word similarity and analogy tasks and on part of speech tagging show better performance of meta embeddings compared to individual embedding sets One advantage of meta embeddings is the increased vocabulary coverage We will release our meta embeddings publicly
91,91,Meta Learning,Learning Context-aware Task Reasoning for Efficient Meta-reinforcement Learning,http://arxiv.org/abs/2003.01373v1,"Despite recent success of deep network-based Reinforcement Learning (RL), it remains elusive to achieve human-level efficiency in learning novel tasks. While previous efforts attempt to address this challenge using meta-learning strategies, they typically suffer from sampling inefficiency with on-policy RL algorithms or meta-overfitting with off-policy learning. In this work, we propose a novel meta-RL strategy to address those limitations. In particular, we decompose the meta-RL problem into three sub-tasks, task-exploration, task-inference and task-fulfillment, instantiated with two deep network agents and a task encoder. During meta-training, our method learns a task-conditioned actor network for task-fulfillment, an explorer network with a self-supervised reward shaping that encourages task-informative experiences in task-exploration, and a context-aware graph-based task encoder for task inference. We validate our approach with extensive experiments on several public benchmarks and the results show that our algorithm effectively performs exploration for task inference, improves sample efficiency during both training and testing, and mitigates the meta-overfitting problem.",92,Despite recent success of deep network based Reinforcement Learning RL it remains elusive to achieve human level efficiency in learning novel tasks While previous efforts attempt to address this challenge using meta learning strategies they typically suffer from sampling inefficiency with on policy RL algorithms or meta overfitting with off policy learning In this work we propose a novel meta RL strategy to address those limitations In particular we decompose the meta RL problem into three sub tasks task exploration task inference and task fulfillment instantiated with two deep network agents and a task encoder During meta training our method learns a task conditioned actor network for task fulfillment an explorer network with a self supervised reward shaping that encourages task informative experiences in task exploration and a context aware graph based task encoder for task inference We validate our approach with extensive experiments on several public benchmarks and the results show that our algorithm effectively performs exploration for task inference improves sample efficiency during both training and testing and mitigates the meta overfitting problem
92,92,Meta Learning,Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,http://arxiv.org/abs/1710.11622v3,"Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.",93,Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently A popular approach to meta learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model or output predictions for new test inputs Alternatively a more recent approach to meta learning aims to acquire deep representations that can be effectively fine tuned via standard gradient descent to new tasks In this paper we consider the meta learning problem from the perspective of universality formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta learner In particular we seek to answer the following question does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm We find that this is indeed true and further find in our experiments that gradient based meta learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models
93,93,Meta Learning,Model-Agnostic Meta-Learning for EEG Motor Imagery Decoding in Brain-Computer-Interfacing,http://arxiv.org/abs/2103.08664v1,"We introduce here the idea of Meta-Learning for training EEG BCI decoders. Meta-Learning is a way of training machine learning systems so they learn to learn. We apply here meta-learning to a simple Deep Learning BCI architecture and compare it to transfer learning on the same architecture. Our Meta-learning strategy operates by finding optimal parameters for the BCI decoder so that it can quickly generalise between different users and recording sessions -- thereby also generalising to new users or new sessions quickly. We tested our algorithm on the Physionet EEG motor imagery dataset. Our approach increased motor imagery classification accuracy between 60% to 80%, outperforming other algorithms under the little-data condition. We believe that establishing the meta-learning or learning-to-learn approach will help neural engineering and human interfacing with the challenges of quickly setting up decoders of neural signals to make them more suitable for daily-life.",94,We introduce here the idea of Meta Learning for training EEG BCI decoders Meta Learning is a way of training machine learning systems so they learn to learn We apply here meta learning to a simple Deep Learning BCI architecture and compare it to transfer learning on the same architecture Our Meta learning strategy operates by finding optimal parameters for the BCI decoder so that it can quickly generalise between different users and recording sessions thereby also generalising to new users or new sessions quickly We tested our algorithm on the Physionet EEG motor imagery dataset Our approach increased motor imagery classification accuracy between 0 to 0 outperforming other algorithms under the little data condition We believe that establishing the meta learning or learning to learn approach will help neural engineering and human interfacing with the challenges of quickly setting up decoders of neural signals to make them more suitable for daily life
94,94,Meta Learning,Guided Meta-Policy Search,http://arxiv.org/abs/1904.00956v2,"Reinforcement learning (RL) algorithms have demonstrated promising results on complex tasks, yet often require impractical numbers of samples since they learn from scratch. Meta-RL aims to address this challenge by leveraging experience from previous tasks so as to more quickly solve new tasks. However, in practice, these algorithms generally also require large amounts of on-policy experience during the meta-training process, making them impractical for use in many problems. To this end, we propose to learn a reinforcement learning procedure in a federated way, where individual off-policy learners can solve the individual meta-training tasks, and then consolidate these solutions into a single meta-learner. Since the central meta-learner learns by imitating the solutions to the individual tasks, it can accommodate either the standard meta-RL problem setting or a hybrid setting where some or all tasks are provided with example demonstrations. The former results in an approach that can leverage policies learned for previous tasks without significant amounts of on-policy data during meta-training, whereas the latter is particularly useful in cases where demonstrations are easy for a person to provide. Across a number of continuous control meta-RL problems, we demonstrate significant improvements in meta-RL sample efficiency in comparison to prior work as well as the ability to scale to domains with visual observations.",95,Reinforcement learning RL algorithms have demonstrated promising results on complex tasks yet often require impractical numbers of samples since they learn from scratch Meta RL aims to address this challenge by leveraging experience from previous tasks so as to more quickly solve new tasks However in practice these algorithms generally also require large amounts of on policy experience during the meta training process making them impractical for use in many problems To this end we propose to learn a reinforcement learning procedure in a federated way where individual off policy learners can solve the individual meta training tasks and then consolidate these solutions into a single meta learner Since the central meta learner learns by imitating the solutions to the individual tasks it can accommodate either the standard meta RL problem setting or a hybrid setting where some or all tasks are provided with example demonstrations The former results in an approach that can leverage policies learned for previous tasks without significant amounts of on policy data during meta training whereas the latter is particularly useful in cases where demonstrations are easy for a person to provide Across a number of continuous control meta RL problems we demonstrate significant improvements in meta RL sample efficiency in comparison to prior work as well as the ability to scale to domains with visual observations
95,95,Meta Learning,Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks,http://arxiv.org/abs/2009.08445v2,"Self-supervised pre-training of transformer models has revolutionized NLP applications. Such pre-training with language modeling objectives provides a useful initial point for parameters that generalize well to new tasks with fine-tuning. However, fine-tuning is still data inefficient -- when there are few labeled examples, accuracy can be low. Data efficiency can be improved by optimizing pre-training directly for future fine-tuning with few examples; this can be treated as a meta-learning problem. However, standard meta-learning techniques require many training tasks in order to generalize; unfortunately, finding a diverse set of such supervised tasks is usually difficult. This paper proposes a self-supervised approach to generate a large, rich, meta-learning task distribution from unlabeled text. This is achieved using a cloze-style objective, but creating separate multi-class classification tasks by gathering tokens-to-be blanked from among only a handful of vocabulary terms. This yields as many unique meta-training tasks as the number of subsets of vocabulary terms. We meta-train a transformer model on this distribution of tasks using a recent meta-learning framework. On 17 NLP tasks, we show that this meta-training leads to better few-shot generalization than language-model pre-training followed by finetuning. Furthermore, we show how the self-supervised tasks can be combined with supervised tasks for meta-learning, providing substantial accuracy gains over previous supervised meta-learning.",96,Self supervised pre training of transformer models has revolutionized NLP applications Such pre training with language modeling objectives provides a useful initial point for parameters that generalize well to new tasks with fine tuning However fine tuning is still data inefficient when there are few labeled examples accuracy can be low Data efficiency can be improved by optimizing pre training directly for future fine tuning with few examples this can be treated as a meta learning problem However standard meta learning techniques require many training tasks in order to generalize unfortunately finding a diverse set of such supervised tasks is usually difficult This paper proposes a self supervised approach to generate a large rich meta learning task distribution from unlabeled text This is achieved using a cloze style objective but creating separate multi class classification tasks by gathering tokens to be blanked from among only a handful of vocabulary terms This yields as many unique meta training tasks as the number of subsets of vocabulary terms We meta train a transformer model on this distribution of tasks using a recent meta learning framework On 0 NLP tasks we show that this meta training leads to better few shot generalization than language model pre training followed by finetuning Furthermore we show how the self supervised tasks can be combined with supervised tasks for meta learning providing substantial accuracy gains over previous supervised meta learning
96,96,Meta Learning,Meta-aprendizado para otimizacao de parametros de redes neurais,http://arxiv.org/abs/2109.13745v1,"The optimization of Artificial Neural Networks (ANNs) is an important task to the success of using these models in real-world applications. The solutions adopted to this task are expensive in general, involving trial-and-error procedures or expert knowledge which are not always available. In this work, we investigated the use of meta-learning to the optimization of ANNs. Meta-learning is a research field aiming to automatically acquiring knowledge which relates features of the learning problems to the performance of the learning algorithms. The meta-learning techniques were originally proposed and evaluated to the algorithm selection problem and after to the optimization of parameters for Support Vector Machines. However, meta-learning can be adopted as a more general strategy to optimize ANN parameters, which motivates new efforts in this research direction. In the current work, we performed a case study using meta-learning to choose the number of hidden nodes for MLP networks, which is an important parameter to be defined aiming a good networks performance. In our work, we generated a base of meta-examples associated to 93 regression problems. Each meta-example was generated from a regression problem and stored: 16 features describing the problem (e.g., number of attributes and correlation among the problem attributes) and the best number of nodes for this problem, empirically chosen from a range of possible values. This set of meta-examples was given as input to a meta-learner which was able to predict the best number of nodes for new problems based on their features. The experiments performed in this case study revealed satisfactory results.",97,The optimization of Artificial Neural Networks ANNs is an important task to the success of using these models in real world applications The solutions adopted to this task are expensive in general involving trial and error procedures or expert knowledge which are not always available In this work we investigated the use of meta learning to the optimization of ANNs Meta learning is a research field aiming to automatically acquiring knowledge which relates features of the learning problems to the performance of the learning algorithms The meta learning techniques were originally proposed and evaluated to the algorithm selection problem and after to the optimization of parameters for Support Vector Machines However meta learning can be adopted as a more general strategy to optimize ANN parameters which motivates new efforts in this research direction In the current work we performed a case study using meta learning to choose the number of hidden nodes for MLP networks which is an important parameter to be defined aiming a good networks performance In our work we generated a base of meta examples associated to 0 regression problems Each meta example was generated from a regression problem and stored 0 features describing the problem e g number of attributes and correlation among the problem attributes and the best number of nodes for this problem empirically chosen from a range of possible values This set of meta examples was given as input to a meta learner which was able to predict the best number of nodes for new problems based on their features The experiments performed in this case study revealed satisfactory results
97,97,Meta Learning,Meta Soft Label Generation for Noisy Labels,http://arxiv.org/abs/2007.05836v2,"The existence of noisy labels in the dataset causes significant performance degradation for deep neural networks (DNNs). To address this problem, we propose a Meta Soft Label Generation algorithm called MSLG, which can jointly generate soft labels using meta-learning techniques and learn DNN parameters in an end-to-end fashion. Our approach adapts the meta-learning paradigm to estimate optimal label distribution by checking gradient directions on both noisy training data and noise-free meta-data. In order to iteratively update soft labels, meta-gradient descent step is performed on estimated labels, which would minimize the loss of noise-free meta samples. In each iteration, the base classifier is trained on estimated meta labels. MSLG is model-agnostic and can be added on top of any existing model at hand with ease. We performed extensive experiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our approach outperforms other state-of-the-art methods by a large margin.",98,The existence of noisy labels in the dataset causes significant performance degradation for deep neural networks DNNs To address this problem we propose a Meta Soft Label Generation algorithm called MSLG which can jointly generate soft labels using meta learning techniques and learn DNN parameters in an end to end fashion Our approach adapts the meta learning paradigm to estimate optimal label distribution by checking gradient directions on both noisy training data and noise free meta data In order to iteratively update soft labels meta gradient descent step is performed on estimated labels which would minimize the loss of noise free meta samples In each iteration the base classifier is trained on estimated meta labels MSLG is model agnostic and can be added on top of any existing model at hand with ease We performed extensive experiments on CIFAR 0 Clothing 0 M and Food 0 N datasets Results show that our approach outperforms other state of the art methods by a large margin
98,98,Meta Learning,Hindsight Foresight Relabeling for Meta-Reinforcement Learning,http://arxiv.org/abs/2109.09031v1,"Meta-reinforcement learning (meta-RL) algorithms allow for agents to learn new behaviors from small amounts of experience, mitigating the sample inefficiency problem in RL. However, while meta-RL agents can adapt quickly to new tasks at test time after experiencing only a few trajectories, the meta-training process is still sample-inefficient. Prior works have found that in the multi-task RL setting, relabeling past transitions and thus sharing experience among tasks can improve sample efficiency and asymptotic performance. We apply this idea to the meta-RL setting and devise a new relabeling method called Hindsight Foresight Relabeling (HFR). We construct a relabeling distribution using the combination of ""hindsight"", which is used to relabel trajectories using reward functions from the training task distribution, and ""foresight"", which takes the relabeled trajectories and computes the utility of each trajectory for each task. HFR is easy to implement and readily compatible with existing meta-RL algorithms. We find that HFR improves performance when compared to other relabeling methods on a variety of meta-RL tasks.",99,Meta reinforcement learning meta RL algorithms allow for agents to learn new behaviors from small amounts of experience mitigating the sample inefficiency problem in RL However while meta RL agents can adapt quickly to new tasks at test time after experiencing only a few trajectories the meta training process is still sample inefficient Prior works have found that in the multi task RL setting relabeling past transitions and thus sharing experience among tasks can improve sample efficiency and asymptotic performance We apply this idea to the meta RL setting and devise a new relabeling method called Hindsight Foresight Relabeling HFR We construct a relabeling distribution using the combination of hindsight which is used to relabel trajectories using reward functions from the training task distribution and foresight which takes the relabeled trajectories and computes the utility of each trajectory for each task HFR is easy to implement and readily compatible with existing meta RL algorithms We find that HFR improves performance when compared to other relabeling methods on a variety of meta RL tasks
99,99,Meta Learning,Meta-Learning Requires Meta-Augmentation,http://arxiv.org/abs/2007.05549v2,"Meta-learning algorithms aim to learn two components: a model that predicts targets for a task, and a base learner that quickly updates that model when given examples from a new task. This additional level of learning can be powerful, but it also creates another potential source for overfitting, since we can now overfit in either the model or the base learner. We describe both of these forms of metalearning overfitting, and demonstrate that they appear experimentally in common meta-learning benchmarks. We then use an information-theoretic framework to discuss meta-augmentation, a way to add randomness that discourages the base learner and model from learning trivial solutions that do not generalize to new tasks. We demonstrate that meta-augmentation produces large complementary benefits to recently proposed meta-regularization techniques.",100,Meta learning algorithms aim to learn two components a model that predicts targets for a task and a base learner that quickly updates that model when given examples from a new task This additional level of learning can be powerful but it also creates another potential source for overfitting since we can now overfit in either the model or the base learner We describe both of these forms of metalearning overfitting and demonstrate that they appear experimentally in common meta learning benchmarks We then use an information theoretic framework to discuss meta augmentation a way to add randomness that discourages the base learner and model from learning trivial solutions that do not generalize to new tasks We demonstrate that meta augmentation produces large complementary benefits to recently proposed meta regularization techniques
